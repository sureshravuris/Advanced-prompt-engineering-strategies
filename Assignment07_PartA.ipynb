{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPUa5zfeAHYC99zYfm3PoUB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/schumbar/CMPE297/blob/main/assignment_07/ShawnChumbar_Assignment07_PartA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 07 Part A: Illustrate Prompt Engineering Techniques\n",
        "\n",
        "## Assignment Description\n",
        "\n",
        "Develop a Colab notebook that demonstrates various prompt engineering techniques discussed in class. For each technique, provide examples of both success and failure cases and show how different prompting strategies address these failures. Techniques to include:  \n",
        "\n",
        "- ICL (In-Context Learning)\n",
        "- CoT (Chain of Thought)\n",
        "- iCOT (Iterative Chain of Thought)\n",
        "- TOT (Tree of Thought)  \n",
        "- GOT (Graph of Thought)  \n",
        "- AOT (Agent of Thought)\n",
        "- RASCEF (Reasoning and Structured Contextual Evidence Framework)  \n",
        "- [REACT (Reasoning and Acting Pattern)](https://til.simonwillison.net/llms/python-react-pattern#:~:text=The%20ReAct%20pattern%20(for%20Reason,results%20back%20into%20the%20LLM.)\n",
        "- [Forest of Thoughts (using LangChain)](https://www.linkedin.com/posts/richard-walker-a18528_forest-of-thoughts-boosting-large-language-activity-7073925128778067968-xAHN/)\n",
        "- [Tree of Thought UI GitHub Repository](https://github.com/mazewoods/tree-of-thought-ui)\n",
        "\n",
        "## References\n",
        "1. [REACT (Reasoning and Acting Pattern)](https://til.simonwillison.net/llms/python-react-pattern#:~:text=The%20ReAct%20pattern%20(for%20Reason,results%20back%20into%20the%20LLM.)\n",
        "2. [Forest of Thoughts (using LangChain)](https://www.linkedin.com/posts/richard-walker-a18528_forest-of-thoughts-boosting-large-language-activity-7073925128778067968-xAHN/)\n",
        "3. [Tree of Thought UI GitHub Repository](https://github.com/mazewoods/tree-of-thought-ui)"
      ],
      "metadata": {
        "id": "1bDay65FcjFr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "First, let's install the OpenAI Python library and set up the API key.\n",
        "**Note:** Replace `'YOUR_OPENAI_API_KEY'` with your actual OpenAI API key."
      ],
      "metadata": {
        "id": "iyUzxwufdWHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install openai\n",
        "!pip install langchain\n",
        "!pip install langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9XRDRzRtxEO",
        "outputId": "8e3c1a48-7906-4fc7-a0bc-1a3c5f3f0550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.7)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.2)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.19)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.143)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain) (3.0.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.7-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
            "Collecting SQLAlchemy<2.0.36,>=1.4 (from langchain_community)\n",
            "  Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.11.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.3.7)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.17 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.3.19)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.143)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.7->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.7->langchain_community) (2.9.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<2.0.36,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.17->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.7->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.7->langchain_community) (2.23.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.2.2)\n",
            "Downloading langchain_community-0.3.7-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
            "Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: SQLAlchemy, python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.36\n",
            "    Uninstalling SQLAlchemy-2.0.36:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.36\n",
            "Successfully installed SQLAlchemy-2.0.35 dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain_community-0.3.7 marshmallow-3.23.1 mypy-extensions-1.0.0 pydantic-settings-2.6.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "open_ai_api_key = userdata.get('OPENAI_KEY')\n",
        "hugging_face_token = userdata.get('HF_TOKEN')"
      ],
      "metadata": {
        "id": "YdJ4qIlltul5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = open_ai_api_key"
      ],
      "metadata": {
        "id": "RVsA8X6otwBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "from openai import OpenAI\n",
        "from langchain_community.llms import OpenAI as LangChainOpenAI\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from typing import List\n",
        "import json"
      ],
      "metadata": {
        "id": "2MhAO968twYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize OpenAI client\n",
        "client = OpenAI(api_key=open_ai_api_key)\n",
        "\n",
        "# Initialize LangChain LLM\n",
        "llm = LangChainOpenAI(temperature=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oM5wcxxDtzeL",
        "outputId": "37af3aa3-74a2-45cf-8370-2b92ee284d54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-9f17bca48abe>:5: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
            "  llm = LangChainOpenAI(temperature=0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. In-Context Learning (ICL)**\n",
        "\n",
        "**Description:** In-context learning involves providing examples within the prompt to help the model understand the task.\n"
      ],
      "metadata": {
        "id": "zCh10krdde1d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Failure Case Without ICL**\n",
        "\n",
        "Let's ask the model to translate a sentence without providing any examples."
      ],
      "metadata": {
        "id": "tG-JRImSer_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Translate the following sentence to French:\\n\\n'I love programming.'\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=60,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content.strip())"
      ],
      "metadata": {
        "id": "UMiCNVEmet38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30cea9d8-fe84-4f17-e79f-b9ded5763d67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"J'adore programmer.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Solution Using ICL**\n",
        "\n",
        "By providing examples, we guide the model to produce the correct translation.\n"
      ],
      "metadata": {
        "id": "RNmXUgTwezPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Translate the following sentences from English to French:\n",
        "\n",
        "'Hello, how are you?' -> 'Bonjour, comment ça va?'\n",
        "'Good morning.' -> 'Bonjour.'\n",
        "'I love programming.' ->\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=60,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content.strip())"
      ],
      "metadata": {
        "id": "QSkPgSQzeygX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6fe46c2-6e7c-46d7-cd5d-a0a04af487bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'J'adore programmer.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Chain of Thought (CoT)**\n",
        "\n",
        "**Description:** CoT prompts the model to generate intermediate reasoning steps before arriving at the final answer."
      ],
      "metadata": {
        "id": "LvRE2p0qeFAn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Failure Case Without CoT**\n",
        "\n",
        "Let's present a math problem to the model without guiding it to think through the steps."
      ],
      "metadata": {
        "id": "g8r8Xr8te6Iv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"If a hen and a half lays an egg and a half in a day and a half, how many eggs do nine hens lay in nine days?\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=60,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "id": "yF1Q13lie8HE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd88f758-4fea-4cfd-e8c5-144e9b2ab51a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To solve this problem, we first need to determine how many eggs one hen lays in one day. \n",
            "\n",
            "If a hen and a half lays an egg and a half in a day and a half, then one hen lays one egg in one day. \n",
            "\n",
            "Therefore, one hen lays 1 egg in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Solution Using CoT**\n",
        "\n",
        "By prompting the model to think step by step, we can get a correct and reasoned answer."
      ],
      "metadata": {
        "id": "oNK40H-1fCXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"If a hen and a half lays an egg and a half in a day and a half, how many eggs do nine hens lay in nine days?\n",
        "\n",
        "Let's think step by step.\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=150,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content.strip())"
      ],
      "metadata": {
        "id": "YT1FG0ZbfBct",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97b4adf0-7997-4524-bb3a-a7deb0adcb29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First, we know that a hen and a half lays an egg and a half in a day and a half. This means that each hen lays 1 egg in 1 day.\n",
            "\n",
            "So, if we have 9 hens, they will lay 9 eggs in 1 day.\n",
            "\n",
            "Therefore, in 9 days, 9 hens will lay 9 eggs each day, resulting in a total of 81 eggs (9 x 9 = 81). \n",
            "\n",
            "So, nine hens will lay 81 eggs in nine days.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Iterated Chain of Thought (iCoT)**\n",
        "\n",
        "**Description:** iCoT involves iteratively refining the model's reasoning process to improve the answer."
      ],
      "metadata": {
        "id": "iFzzdcnzeH5d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Failure Case Without iCoT**\n",
        "\n",
        "Let's ask a complex logic puzzle without iterative refinement.\n"
      ],
      "metadata": {
        "id": "cbbzviwBf2HJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"You have 10 bags with 10 coins each. One bag contains counterfeit coins weighing 1 gram each; genuine coins weigh 1.1 grams each. Using a digital scale only once, how do you determine which bag has the counterfeit coins?\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=150,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content.strip())"
      ],
      "metadata": {
        "id": "GtVhlG8if8l7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "291ca9ec-b72c-46e6-de04-19b4daa7949c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To determine which bag contains the counterfeit coins, follow these steps:\n",
            "\n",
            "1. Label the bags from 1 to 10.\n",
            "2. Take 1 coin from bag 1, 2 coins from bag 2, 3 coins from bag 3, and so on until you have 10 coins from bag 10.\n",
            "3. Place all the coins on the digital scale and weigh them.\n",
            "4. If all the coins were genuine, the total weight should be 550 grams (1.1 grams x 10 coins x 10 bags).\n",
            "5. The total weight will be less than 550 grams if one of the bags contains counterfeit coins.\n",
            "6. The difference in weight will indicate which bag contains the counterfeit coins. For example,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Solution Using iCoT**\n",
        "\n",
        "We can prompt the model to refine its reasoning iteratively."
      ],
      "metadata": {
        "id": "QFG-APi9gDXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"You have 10 bags with 10 coins each. One bag contains counterfeit coins weighing 1 gram each; genuine coins weigh 1.1 grams each. Using a digital scale only once, how do you determine which bag has the counterfeit coins?\n",
        "\n",
        "Let's think step by step.\n",
        "\n",
        "[First Attempt]\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=250,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "first_attempt = response.choices[0].message.content.strip()\n",
        "print(first_attempt)\n",
        "\n",
        "prompt += f\"\\n{first_attempt}\\n\\n[Refined Attempt]\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=250,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "refined_attempt = response.choices[0].message.content.strip()\n",
        "print(refined_attempt)"
      ],
      "metadata": {
        "id": "idrUcU-ngApJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b65ddae4-86f1-489f-bc97-b9406893d846"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Take one coin from the first bag, two coins from the second bag, three coins from the third bag, and so on until you have ten coins from the tenth bag.\n",
            "2. Weigh all the coins together on the digital scale.\n",
            "3. If all the coins were genuine, the total weight should be 55 grams (10 coins x 1.1 grams each).\n",
            "4. The total weight will be less than 55 grams if the bag with counterfeit coins is included in the mix.\n",
            "5. The difference in weight will indicate which bag contains the counterfeit coins.\n",
            "\n",
            "This method may not be the most efficient as it requires multiple steps and calculations. Let's try a different approach.\n",
            "\n",
            "[Second Attempt]\n",
            "\n",
            "1. Take one coin from the first bag, two coins from the second bag, three coins from the third bag, and so on until you have ten coins from the tenth bag.\n",
            "2. Weigh all the coins together on the digital scale.\n",
            "3. The total weight will be less than 55 grams if the bag with counterfeit coins is included in the mix.\n",
            "4. Remove one coin from the bag corresponding to the difference in weight (e.g., if the total weight is 54 grams, the counterfeit coins are in\n",
            "1. Take one coin from the first bag, two coins from the second bag, three coins from the third bag, and so on until you have ten coins from the tenth bag.\n",
            "2. Weigh all the coins together on the digital scale.\n",
            "3. If all the coins were genuine, the total weight should be 550 grams (10 bags x 10 coins x 1.1 grams each).\n",
            "4. The total weight will be less than 550 grams if the bag with counterfeit coins is included in the mix.\n",
            "5. The difference in weight will indicate which bag contains the counterfeit coins.\n",
            "6. For example, if the total weight is 545 grams, the bag with the counterfeit coins is the fifth bag (as each genuine coin weighs 1.1 grams, so the total weight should be 550 grams).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First Attempt Output Above.\n",
        "Now, we refine the reasoning below:"
      ],
      "metadata": {
        "id": "JeJ7RQ59gGYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt += f\"\\n{first_attempt}\\n\\n[Refined Attempt]\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=250,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "refined_attempt = response.choices[0].message.content.strip()\n",
        "print(refined_attempt)"
      ],
      "metadata": {
        "id": "ts8gsARMgJwu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e09879d5-506d-46ea-f06f-cb5130f24f77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Take one coin from the first bag, two coins from the second bag, three coins from the third bag, and so on until you have ten coins from the tenth bag.\n",
            "2. Weigh all the coins together on the digital scale.\n",
            "3. If all the coins were genuine, the total weight should be 55 grams (10 coins x 1.1 grams each).\n",
            "4. The total weight will be less than 55 grams if the bag with counterfeit coins is included in the mix.\n",
            "5. The difference in weight will indicate which bag contains the counterfeit coins.\n",
            "\n",
            "This refined attempt is the most efficient way to determine which bag contains the counterfeit coins using the digital scale only once.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Algorithm of Thought (AoT)**\n",
        "\n",
        "**Description:** AoT guides the model to follow algorithmic reasoning steps, similar to how an algorithm operates."
      ],
      "metadata": {
        "id": "QGtg-iZieNfw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Failure Case Without AoT**\n",
        "\n",
        "Ask the model to sort numbers without guiding it through an algorithm."
      ],
      "metadata": {
        "id": "IQ3iRP_agVC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Sort the following numbers in ascending order: 42, 23, 17, 13, 99, 8.\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=50,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content.strip())"
      ],
      "metadata": {
        "id": "y1Tjs1AngVXW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "880ae4d2-28dd-4cd9-842a-1b5815540b27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8, 13, 17, 23, 42, 99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Solution Using AoT**\n",
        "\n",
        "Provide an algorithmic structure to guide the model."
      ],
      "metadata": {
        "id": "lwX5lbKvgbb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Sort the following numbers in ascending order: 42, 23, 17, 13, 99, 8.\n",
        "\n",
        "Algorithm:\n",
        "1. List the numbers.\n",
        "2. Compare each number with the others.\n",
        "3. Arrange them from the smallest to the largest.\n",
        "\n",
        "Solution:\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=100,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content.strip())"
      ],
      "metadata": {
        "id": "gMJCLw3zgfqC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d851d1c5-25ec-4a9c-dee2-dafd0063cd5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8, 13, 17, 23, 42, 99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. ReAct (Reasoning and Acting)**\n",
        "\n",
        "**Description:** ReAct combines reasoning and acting by interleaving thought processes with actions, such as retrieving information."
      ],
      "metadata": {
        "id": "lg6p024tePtw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Failure Case Without ReAct**\n",
        "\n",
        "Ask the model a question requiring current knowledge."
      ],
      "metadata": {
        "id": "R96LrBm2gmbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"What is the latest movie released by Christopher Nolan?\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=60,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "id": "h8mCbmwWgo33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0922ff85-9dfd-4679-870b-ce37ff329c00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The latest movie released by Christopher Nolan is \"Tenet,\" which was released in 2020.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Solution Using ReAct**\n",
        "Guide the model to reason and simulate an action to obtain updated information."
      ],
      "metadata": {
        "id": "1OjhjJlggsp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Question: What is the latest movie released by Christopher Nolan?\n",
        "\n",
        "Let's think step by step.\n",
        "\n",
        "[Thought]: I need to find the most recent movie by Christopher Nolan.\n",
        "[Action]: Search('Latest Christopher Nolan movie')\n",
        "[Observation]: The latest movie is 'Oppenheimer' released in 2023.\n",
        "[Answer]: The latest movie released by Christopher Nolan is 'Oppenheimer' in 2023.\"\"\"\n",
        "\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "fMfAdH0ngwBT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5698da4b-955c-4d25-e26f-e8643e372d81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the latest movie released by Christopher Nolan?\n",
            "\n",
            "Let's think step by step.\n",
            "\n",
            "[Thought]: I need to find the most recent movie by Christopher Nolan.\n",
            "[Action]: Search('Latest Christopher Nolan movie')\n",
            "[Observation]: The latest movie is 'Oppenheimer' released in 2023.\n",
            "[Answer]: The latest movie released by Christopher Nolan is 'Oppenheimer' in 2023.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6. RASCEF Framework**\n",
        "\n",
        "**Description:** RASCEF is a prompting framework that stands for Role, Audience, Style, Content, Emphasis, and Format. It helps structure prompts for better outputs."
      ],
      "metadata": {
        "id": "hATpmor9eSUd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Failure Case Without RASCEF**\n",
        "\n",
        "Ask the model to write an email without specific guidelines.\n"
      ],
      "metadata": {
        "id": "gtG39DMZg30T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Write an email to a potential client introducing our company.\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=150,\n",
        "    temperature=0.5\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content.strip())"
      ],
      "metadata": {
        "id": "ynRIypy_g4BG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8fd9589-0277-4d74-feff-4ca1eed65b79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subject: Introduction to Our Company - Your Potential Partner in Success\n",
            "\n",
            "Dear [Client's Name],\n",
            "\n",
            "I hope this email finds you well. I am reaching out to introduce our company, [Company Name], and explore potential partnership opportunities with your business.\n",
            "\n",
            "At [Company Name], we specialize in providing innovative solutions to help companies like yours achieve their goals and drive success. Our team of experts is dedicated to delivering top-notch services in [list services or products your company offers], tailored to meet the specific needs and objectives of each client.\n",
            "\n",
            "With a proven track record of success and a commitment to excellence, we are confident that we can add value to your business and help you reach new heights. By partnering with us, you can expect:\n",
            "\n",
            "- Customized solutions designed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Solution Using RASCEF**\n",
        "\n",
        "Provide detailed instructions using the RASCEF framework."
      ],
      "metadata": {
        "id": "rwFGLE4yg9tk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"[Role]: You are a professional business assistant.\n",
        "[Audience]: The recipient is a potential client interested in our services.\n",
        "[Style]: The email should be formal and persuasive.\n",
        "[Content]: Introduce our company, highlight our key services, and propose a meeting.\n",
        "[Emphasis]: Emphasize our commitment to quality and customer satisfaction.\n",
        "[Format]: Use proper email formatting with a subject line, greeting, body, and closing.\n",
        "\n",
        "Please compose the email.\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=250,\n",
        "    temperature=0.5\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content.strip())"
      ],
      "metadata": {
        "id": "Pv-9AYBwg405",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23acee24-43db-4901-8e85-6333ea603b3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subject: Invitation to Learn More About Our Business Services\n",
            "\n",
            "Dear [Recipient's Name],\n",
            "\n",
            "I hope this email finds you well. My name is [Your Name], and I am a professional business assistant at [Company Name]. I am reaching out to introduce our company and the services we offer that could be of great benefit to your business.\n",
            "\n",
            "At [Company Name], we specialize in providing top-notch business solutions tailored to meet the specific needs of our clients. Our key services include but are not limited to:\n",
            "\n",
            "1. Business consulting and strategic planning\n",
            "2. Marketing and branding strategies\n",
            "3. Financial analysis and planning\n",
            "4. Administrative support and project management\n",
            "\n",
            "We take pride in our commitment to quality and customer satisfaction. Our team of experts is dedicated to delivering exceptional results and exceeding our clients' expectations. We strive to build long-lasting relationships based on trust, integrity, and professionalism.\n",
            "\n",
            "I would like to propose a meeting to discuss how our services can help your business achieve its goals and objectives. This meeting would provide us with the opportunity to learn more about your business needs and how we can best support you in achieving success.\n",
            "\n",
            "Please let me know a convenient time for you to meet, either in person or virtually, and I will be happy to arrange a meeting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7. Tree of Thought (ToT)**\n",
        "\n",
        "**Description:** Tree of Thought involves generating multiple reasoning paths (branches) and exploring them to find the best solution."
      ],
      "metadata": {
        "id": "es80ALX_h8nD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Failure Case Without ToT**\n",
        "\n",
        "Consider a riddle that requires exploring multiple possibilities."
      ],
      "metadata": {
        "id": "GGGVlS3kh_IM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"A traveler comes to a fork in the road and needs to get to the village. One path leads to the village; the other leads to a dead end. Two twins are standing at the fork: one always tells the truth, and one always lies. The traveler can ask one question to one twin to determine the correct path. What should they ask?\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=150,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content.strip())"
      ],
      "metadata": {
        "id": "T12MqBsyiBav",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a949ab24-779d-4f4e-a213-ba67c5617274"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The traveler should ask one of the twins, \"If I were to ask your twin which path leads to the village, what would they say?\" \n",
            "\n",
            "If the traveler asks the truth-telling twin, they would point to the path that the lying twin would say leads to the dead end. If the traveler asks the lying twin, they would also point to the path that the lying twin would say leads to the dead end. In either case, the traveler should choose the opposite path that the twin points to in order to reach the village.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Solution Using ToT**\n",
        "\n",
        "Use the Tree of Thought to explore different reasoning paths."
      ],
      "metadata": {
        "id": "fK3FFLp-iHpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"A traveler comes to a fork in the road and needs to get to the village. One path leads to the village; the other leads to a dead end. Two twins are standing at the fork: one always tells the truth, and one always lies. The traveler can ask one question to one twin to determine the correct path. What should they ask?\n",
        "\n",
        "Let's consider different possibilities:\n",
        "\n",
        "- **Option 1:** Ask Twin A, \"Is your twin the liar?\"\n",
        "  - If Twin A is the truth-teller, he will say \"Yes.\"\n",
        "  - If Twin A is the liar, he will also say \"Yes.\"\n",
        "  - This doesn't help distinguish the paths.\n",
        "\n",
        "- **Option 2:** Ask, \"If I were to ask your twin which path leads to the village, what would they say?\"\n",
        "  - This creates a paradox that reveals the correct path.\n",
        "\n",
        "**Answer:** The traveler should ask one twin, \"If I asked your twin which path leads to the village, what would they say?\" Then, take the opposite path.\"\"\"\n",
        "\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "85fYcgesiKrO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cddeda0b-b230-427a-c0b4-e75cb87d3f42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A traveler comes to a fork in the road and needs to get to the village. One path leads to the village; the other leads to a dead end. Two twins are standing at the fork: one always tells the truth, and one always lies. The traveler can ask one question to one twin to determine the correct path. What should they ask?\n",
            "\n",
            "Let's consider different possibilities:\n",
            "\n",
            "- **Option 1:** Ask Twin A, \"Is your twin the liar?\"\n",
            "  - If Twin A is the truth-teller, he will say \"Yes.\"\n",
            "  - If Twin A is the liar, he will also say \"Yes.\"\n",
            "  - This doesn't help distinguish the paths.\n",
            "\n",
            "- **Option 2:** Ask, \"If I were to ask your twin which path leads to the village, what would they say?\"\n",
            "  - This creates a paradox that reveals the correct path.\n",
            "\n",
            "**Answer:** The traveler should ask one twin, \"If I asked your twin which path leads to the village, what would they say?\" Then, take the opposite path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **8. Graph of Thought (GoT)**\n",
        "\n",
        "**Description:** GoT extends the idea of ToT by allowing for a graph structure where reasoning paths can merge or diverge, enabling the model to consider multiple interconnected reasoning steps."
      ],
      "metadata": {
        "id": "6xfvtXE6iPkL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Failure Case Without GoT**\n",
        "\n",
        "Attempt to solve a complex problem that benefits from interconnected reasoning."
      ],
      "metadata": {
        "id": "ug2mbNX0jIaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"You have eight balls, one of which is slightly heavier, and a balance scale. How can you find the heavier ball using the scale only twice?\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=200,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content.strip())"
      ],
      "metadata": {
        "id": "laLMMr16jM1K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16751150-478b-4df4-f405-cc4de3b43aff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Divide the balls into three groups: Group A with three balls, Group B with three balls, and Group C with two balls.\n",
            "2. Weigh Group A against Group B on the balance scale.\n",
            "3. If Group A and Group B are balanced, the heavier ball is in Group C. Weigh one ball from Group C against another ball from Group C to find the heavier ball.\n",
            "4. If Group A and Group B are not balanced, take the heavier group and divide it into three individual balls: one ball in Group D, one ball in Group E, and one ball in Group F.\n",
            "5. Weigh one ball from Group D against one ball from Group E.\n",
            "6. If one of the balls is heavier, that ball is the heavier ball. If they are balanced, the heavier ball is in Group F. Weigh one ball from Group F against another ball from Group F to find the heavier ball.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Solution Using GoT**\n",
        "\n",
        "Use a graph-based reasoning approach to explore multiple paths."
      ],
      "metadata": {
        "id": "Hf9PxMKDjQn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"You have eight balls, one of which is slightly heavier, and a balance scale. How can you find the heavier ball using the scale only twice?\n",
        "\n",
        "Let's consider the possible weighing strategies:\n",
        "\n",
        "1. **First Weighing:**\n",
        "   - Weigh 3 balls against 3 balls.\n",
        "     - **Case A:** They balance.\n",
        "       - The heavier ball is among the remaining 2 balls.\n",
        "       - **Second Weighing:**\n",
        "         - Weigh the remaining 2 balls against each other.\n",
        "     - **Case B:** One side is heavier.\n",
        "       - The heavier ball is among the 3 balls on the heavier side.\n",
        "       - **Second Weighing:**\n",
        "         - Choose any 2 of the 3 balls and weigh them.\n",
        "           - If they balance, the heavier ball is the one not weighed.\n",
        "           - If they don't, the heavier side contains the heavier ball.\n",
        "\n",
        "2. **Alternative Strategy:**\n",
        "   - ...\n",
        "\n",
        "**Answer:** Use the first strategy to find the heavier ball in two weighings.\"\"\"\n",
        "\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "EOrknIAnjSeB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6383a56b-ce68-4f61-f93a-9c3115ee0799"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You have eight balls, one of which is slightly heavier, and a balance scale. How can you find the heavier ball using the scale only twice?\n",
            "\n",
            "Let's consider the possible weighing strategies:\n",
            "\n",
            "1. **First Weighing:**\n",
            "   - Weigh 3 balls against 3 balls.\n",
            "     - **Case A:** They balance.\n",
            "       - The heavier ball is among the remaining 2 balls.\n",
            "       - **Second Weighing:**\n",
            "         - Weigh the remaining 2 balls against each other.\n",
            "     - **Case B:** One side is heavier.\n",
            "       - The heavier ball is among the 3 balls on the heavier side.\n",
            "       - **Second Weighing:**\n",
            "         - Choose any 2 of the 3 balls and weigh them.\n",
            "           - If they balance, the heavier ball is the one not weighed.\n",
            "           - If they don't, the heavier side contains the heavier ball.\n",
            "\n",
            "2. **Alternative Strategy:**\n",
            "   - ...\n",
            "\n",
            "**Answer:** Use the first strategy to find the heavier ball in two weighings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **9. Agent of Thought (AoT)**\n",
        "\n",
        "**Description:** AoT involves using an agent-based approach where the model acts as an agent that can perform actions like calculations, searches, or accessing tools to aid in problem-solving."
      ],
      "metadata": {
        "id": "nMy0r1-QjYSG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Failure Case Without AoT**\n",
        "\n",
        "Ask a question that requires the model to perform calculations beyond its capabilities."
      ],
      "metadata": {
        "id": "XCmFnFNmjbG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Calculate the square root of 12345.\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=50,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content.strip())"
      ],
      "metadata": {
        "id": "CCVvnCGSjcst",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a2d665d-b803-4fc4-f7ec-e6cfd4b16b20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The square root of 12345 is approximately 111.108.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Solution Using AoT**\n",
        "\n",
        "Leverage the agent to perform the calculation accurately."
      ],
      "metadata": {
        "id": "aOPjzxTMjhmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"You are a math assistant that can perform precise calculations.\n",
        "\n",
        "Question: Calculate the square root of 12345.\n",
        "\n",
        "Agent Action: Compute sqrt(12345)\n",
        "\n",
        "Result: 111.10805551354\n",
        "\n",
        "Answer: The square root of 12345 is approximately 111.10805551354.\"\"\"\n",
        "\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "UVBXuLuVji03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f3e8d57-58d3-4ff6-af7a-7476c074786a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are a math assistant that can perform precise calculations.\n",
            "\n",
            "Question: Calculate the square root of 12345.\n",
            "\n",
            "Agent Action: Compute sqrt(12345)\n",
            "\n",
            "Result: 111.10805551354\n",
            "\n",
            "Answer: The square root of 12345 is approximately 111.10805551354.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **10. Forest of Thoughts (Using LangChain)**\n",
        "\n",
        "**Description:** Forest of Thoughts expands upon Tree of Thought by generating multiple trees (forests) of reasoning and selecting the best paths among them. This technique often utilizes external tools like LangChain to manage complex reasoning processes."
      ],
      "metadata": {
        "id": "MKWvOl0PjoxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "from langchain.llms import OpenAI\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "\n",
        "# Initialize LangChain LLM\n",
        "llm = OpenAI(temperature=0)\n",
        "\n",
        "# Define the problem\n",
        "problem = \"\"\"Design a plan to reduce traffic congestion in a city.\"\"\""
      ],
      "metadata": {
        "id": "80IS-ieC-Ba0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **Failure Case Without Forest of Thoughts**\n",
        "\n",
        "Attempt to solve an ambiguous problem without considering multiple reasoning trees."
      ],
      "metadata": {
        "id": "47m-Wd82jrrD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Failure Case Without FoT\n",
        "response_simple = llm(problem)\n",
        "print(\"**Response Without Forest of Thoughts:**\\n\")\n",
        "print(response_simple)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LowsnkVv-KU-",
        "outputId": "dc913614-2a4c-4674-a09c-b2ac48a583c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-6fce82c1d5aa>:2: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response_simple = llm(problem)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Response Without Forest of Thoughts:**\n",
            "\n",
            "\n",
            "\n",
            "1. Improve Public Transportation: One of the most effective ways to reduce traffic congestion is to improve the public transportation system. This can include increasing the frequency of buses and trains, expanding routes to cover more areas, and providing incentives for people to use public transportation such as discounted fares or free passes.\n",
            "\n",
            "2. Encourage Carpooling: Encouraging carpooling can significantly reduce the number of cars on the road. This can be done by providing designated carpool lanes, offering incentives for carpooling such as reduced toll fees or parking fees, and promoting carpooling through advertising campaigns.\n",
            "\n",
            "3. Implement Congestion Pricing: Congestion pricing is a system where drivers are charged a fee for entering certain congested areas during peak hours. This can help reduce traffic by encouraging people to use alternative routes or modes of transportation.\n",
            "\n",
            "4. Improve Traffic Management: Implementing better traffic management strategies such as synchronized traffic lights, roundabouts, and one-way streets can help improve the flow of traffic and reduce congestion.\n",
            "\n",
            "5. Create Bike Lanes and Walkways: Providing safe and convenient bike lanes and walkways can encourage people to use alternative modes of transportation, reducing the number of cars on the road.\n",
            "\n",
            "6. Introduce Flexible Work Hours: Many people commute to work during peak hours\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using OpenAI's ChatCompletion API\n"
      ],
      "metadata": {
        "id": "uis4tIDx-WM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternative using OpenAI's ChatCompletion API\n",
        "import openai\n",
        "openai.api_key = open_ai_api_key\n",
        "\n",
        "response_chat = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[{\"role\": \"user\", \"content\": problem}],\n",
        "    max_tokens=250,\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "print(\"\\n**Response Using ChatCompletion API:**\\n\")\n",
        "print(response_chat.choices[0].message.content.strip())"
      ],
      "metadata": {
        "id": "HAZsKVAp-eBl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "604c8715-49c4-42a5-e300-d709befc3957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "**Response Using ChatCompletion API:**\n",
            "\n",
            "1. Implement a comprehensive public transportation system: Increase the frequency and coverage of buses, trains, and other forms of public transportation to encourage more people to use these services instead of driving their cars.\n",
            "\n",
            "2. Create dedicated bus lanes and bike lanes: Prioritize public transportation and cycling by designating lanes specifically for buses and bicycles, which can help reduce congestion on the roads.\n",
            "\n",
            "3. Implement congestion pricing: Charge drivers a fee for entering high-traffic areas during peak hours to encourage carpooling, using public transportation, or finding alternative routes.\n",
            "\n",
            "4. Promote telecommuting and flexible work hours: Encourage businesses to allow employees to work remotely or adjust their schedules to avoid peak traffic times, reducing the number of cars on the road during rush hours.\n",
            "\n",
            "5. Improve traffic flow through intelligent traffic management systems: Install traffic lights that adjust their timing based on real-time traffic conditions, use sensors to monitor traffic flow, and provide real-time updates to drivers on congestion and alternate routes.\n",
            "\n",
            "6. Encourage carpooling and ridesharing: Incentivize carpooling and ridesharing through programs that offer discounts on tolls, parking, or gas, and create designated carpool lanes to make the experience more efficient for participants.\n",
            "\n",
            "7.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **Solution Using Forest of Thoughts**\n",
        "\n",
        "Utilize LangChain to generate multiple detailed plans and select the most effective one."
      ],
      "metadata": {
        "id": "ncNjyeXpjwxL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Defining Forest of Thoughts Prompt Template"
      ],
      "metadata": {
        "id": "URxIbHtl-fcl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Forest of Thoughts prompt template\n",
        "prompt_template = \"\"\"\n",
        "Please explore multiple reasoning paths to solve the following problem. For each path:\n",
        "\n",
        "1. Provide your reasoning steps.\n",
        "2. Present the solution.\n",
        "\n",
        "After considering all paths, evaluate which solution effectively addresses the problem, and explain why it is the best approach.\n",
        "\n",
        "Problem:\n",
        "{problem}\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"problem\"],\n",
        "    template=prompt_template,\n",
        ")"
      ],
      "metadata": {
        "id": "Ue4tV-PK-hw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating and Running the LLMChain with the Prompt"
      ],
      "metadata": {
        "id": "1IwPujFZ-lAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the LLMChain with the prompt\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "\n",
        "# Run the LLMChain with the problem\n",
        "response_fot = llm_chain.run(problem=problem)"
      ],
      "metadata": {
        "id": "P1gJyZut-o2s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a514f5f-d0f9-4292-b495-276085b2bdc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-ec5a53848de1>:2: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
            "<ipython-input-29-ec5a53848de1>:5: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response_fot = llm_chain.run(problem=problem)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n**Response Using Forest of Thoughts:**\\n\")\n",
        "print(response_fot)"
      ],
      "metadata": {
        "id": "3PCCCGT1jyaI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acce2e1b-ff01-4cd5-fc08-da93c8123b09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "**Response Using Forest of Thoughts:**\n",
            "\n",
            "\n",
            "Path 1:\n",
            "1. Identify the main causes of traffic congestion in the city, such as high population density, inadequate public transportation, and road construction.\n",
            "2. Develop a plan to address each cause, such as implementing a carpooling program, expanding public transportation options, and coordinating road construction projects to minimize disruptions.\n",
            "3. Consider implementing congestion pricing, where drivers are charged a fee for entering certain congested areas during peak hours.\n",
            "4. Encourage alternative modes of transportation, such as biking or walking, by creating dedicated lanes and providing incentives for using these methods.\n",
            "5. Increase the use of technology, such as traffic sensors and real-time navigation apps, to help drivers avoid congested areas.\n",
            "6. Educate the public about the benefits of reducing traffic congestion and the importance of individual actions in achieving this goal.\n",
            "7. Continuously monitor and evaluate the effectiveness of the plan and make adjustments as needed.\n",
            "\n",
            "Solution: A comprehensive plan that addresses the main causes of traffic congestion and includes a combination of strategies, such as carpooling, public transportation, congestion pricing, alternative modes of transportation, technology, and education, can effectively reduce traffic congestion in the city.\n",
            "\n",
            "Path 2:\n",
            "1. Analyze the current traffic patterns and identify the areas with the highest congestion.\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **11. Tree of Thought UI**\n",
        "\n",
        "**Description:** The Tree of Thought UI is a tool that visually represents the reasoning paths taken by the model. It helps in understanding and debugging the reasoning process."
      ],
      "metadata": {
        "id": "DT-1ywspj2fm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Failure Case without Tree of Thought UI (Tot)"
      ],
      "metadata": {
        "id": "wfPt1rI3_N1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the problem\n",
        "problem = \"How can we sustainably increase crop yields in agriculture?\"\n",
        "\n",
        "# Get a simple response from the LLM\n",
        "response_simple = llm(problem)\n",
        "print(\"**Response Without Tree of Thought:**\\n\")\n",
        "print(response_simple)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vboqybP0_XNX",
        "outputId": "35811d94-0a3c-44f1-c151-efc01d610a99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Response Without Tree of Thought:**\n",
            "\n",
            "\n",
            "\n",
            "1. Use sustainable farming practices: Sustainable farming practices such as crop rotation, conservation tillage, and integrated pest management can help maintain soil health, reduce erosion, and minimize the use of chemical inputs.\n",
            "\n",
            "2. Improve soil health: Healthy soil is essential for sustainable crop production. Practices such as cover cropping, composting, and reduced tillage can improve soil fertility, structure, and water-holding capacity.\n",
            "\n",
            "3. Use precision agriculture techniques: Precision agriculture uses technology such as GPS, sensors, and drones to collect data and optimize farming practices. This can help farmers make more informed decisions about planting, fertilizing, and irrigating their crops, leading to higher yields.\n",
            "\n",
            "4. Invest in research and development: Governments and private organizations should invest in research and development to develop new and improved crop varieties, as well as innovative farming techniques that can increase yields sustainably.\n",
            "\n",
            "5. Implement water management strategies: Water scarcity is a major challenge in agriculture. Implementing water management strategies such as drip irrigation, rainwater harvesting, and efficient irrigation systems can help conserve water and increase crop yields.\n",
            "\n",
            "6. Use organic and natural fertilizers: Chemical fertilizers can have negative impacts on soil health and the environment. Using organic and natural fertilizers, such as compost and manure, can improve soil\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Solution Using Tree of Thought UI\n"
      ],
      "metadata": {
        "id": "Ishaq9fX_bdq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Defining Tree of Thought Prompt"
      ],
      "metadata": {
        "id": "TUQa8RM9_jsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = \"\"\"\n",
        "Solve the following problem by exploring multiple possible actions at each step, considering their consequences, and choosing the best path. Represent your reasoning as a tree where each branch represents a different action.\n",
        "\n",
        "Problem:\n",
        "{problem}\n",
        "\n",
        "Instructions:\n",
        "\n",
        "- At each step, list all possible actions.\n",
        "- For each action, describe the resulting state.\n",
        "- Continue exploring until you reach the goal state.\n",
        "- If a path leads to a dead end, backtrack and explore other paths.\n",
        "- Provide the sequence of actions that leads to the solution.\n",
        "\n",
        "Your response should include the reasoning process and the final solution.\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"problem\"],\n",
        "    template=prompt_template,\n",
        ")"
      ],
      "metadata": {
        "id": "oLZVid9t_hX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating and Running the LLMChain with Prompt"
      ],
      "metadata": {
        "id": "9HjLti4__myY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the LLMChain with the prompt\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "\n",
        "# Run the LLMChain with the problem\n",
        "response_tot = llm_chain.run(problem=problem)"
      ],
      "metadata": {
        "id": "0oIxTaZc_p4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the response from the ToT chain\n",
        "print(\"\\n**Response Using Tree of Thought:**\\n\")\n",
        "print(response_tot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jckgB0C7_OUn",
        "outputId": "20f74ba3-cdfe-43cc-8f4a-dd5cdeda44f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "**Response Using Tree of Thought:**\n",
            "\n",
            "\n",
            "Possible Actions:\n",
            "1. Implement crop rotation\n",
            "2. Use cover crops\n",
            "3. Improve soil health through organic matter\n",
            "4. Use precision farming techniques\n",
            "5. Implement integrated pest management\n",
            "6. Use genetically modified crops\n",
            "7. Increase irrigation and water management\n",
            "8. Use sustainable fertilizers\n",
            "9. Implement agroforestry practices\n",
            "10. Use sustainable farming practices\n",
            "\n",
            "Reasoning Process:\n",
            "1. Implement crop rotation:\n",
            "- Resulting state: Improved soil health, reduced pest and disease pressure, increased nutrient availability, reduced erosion.\n",
            "- This action can lead to sustainable increase in crop yields by allowing the soil to replenish nutrients and reducing the risk of pests and diseases.\n",
            "\n",
            "2. Use cover crops:\n",
            "- Resulting state: Improved soil health, reduced erosion, increased water retention, reduced weed growth.\n",
            "- This action can lead to sustainable increase in crop yields by providing additional nutrients to the soil, reducing soil erosion, and suppressing weed growth.\n",
            "\n",
            "3. Improve soil health through organic matter:\n",
            "- Resulting state: Increased soil fertility, improved water retention, reduced erosion.\n",
            "- This action can lead to sustainable increase in crop yields by providing essential nutrients to the soil, improving water retention, and reducing soil erosion.\n",
            "\n",
            "4. Use precision farming techniques:\n",
            "- Resulting state:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Usage**\n",
        "\n",
        "While we cannot demonstrate the UI in this notebook, you can explore the [Tree of Thought UI GitHub Repository](https://github.com/mazewoods/tree-of-thought-ui) for implementation details."
      ],
      "metadata": {
        "id": "Am9hlaafj6Cd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "W697ofFBAqa5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Conclusion**\n",
        "\n",
        "This notebook has explored a wide range of prompt engineering techniques, showcasing their potential to enhance the reasoning and response capabilities of language models like GPT-3.5 and GPT-4. The techniques demonstrated include both foundational and advanced methods:\n",
        "\n",
        "### Foundational Techniques\n",
        "- **In-Context Learning (ICL)**\n",
        "- **Chain of Thought (CoT)**\n",
        "- **Iterated Chain of Thought (iCoT)**\n",
        "- **Algorithm of Thought (AoT)**\n",
        "- **ReAct (Reasoning and Acting)**\n",
        "- **RASCEF Framework**\n",
        "\n",
        "### Advanced Techniques\n",
        "- **Tree of Thought (ToT)**\n",
        "- **Graph of Thought (GoT)**\n",
        "- **Agent of Thought (AoT)**\n",
        "- **Forest of Thoughts (using LangChain)**\n",
        "- **Tree of Thought UI**\n",
        "\n",
        "These methods enable language models to produce more accurate, contextually appropriate, and sophisticated responses by guiding them through structured reasoning paths, iterated learning loops, and agent-based problem-solving strategies. Advanced techniques like Tree of Thought (ToT) and Forest of Thoughts allow models to explore multiple reasoning paths and interact with external tools, significantly enhancing their problem-solving potential.\n",
        "\n",
        "### Additional Resources\n",
        "- **Forest of Thoughts Article:** [Forest of Thoughts: Boosting Large Language Model Reasoning with Multiple Sequences](https://www.linkedin.com/posts/richard-walker-a18528_forest-of-thoughts-boosting-large-language-activity-7073925128778067968-xAHN/)\n",
        "- **Tree of Thought UI GitHub Repository:** [mazewoods/tree-of-thought-ui](https://github.com/mazewoods/tree-of-thought-ui)\n",
        "\n",
        "**Note:** Some advanced techniques, such as Tree of Thought (ToT), Graph of Thought (GoT), and Forest of Thoughts, involve recursive reasoning and external tools like LangChain, requiring additional setup and a specialized development environment. These approaches are introduced here conceptually and are ideal for applications that demand highly complex reasoning and tool integration.\n",
        "\n",
        "By integrating these techniques, we can unlock the full potential of language models, transforming them into powerful tools for tackling diverse and challenging tasks."
      ],
      "metadata": {
        "id": "NRY1cm6veT25"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** Some advanced techniques like Tree of Thought (ToT), Graph of Thought (GoT), and Forest of Thoughts require complex implementations and are beyond the scope of this notebook. They often involve recursive reasoning paths and external tools like LangChain for management, which are better suited for specialized development environments."
      ],
      "metadata": {
        "id": "I8gvlUR1hIC0"
      }
    }
  ]
}