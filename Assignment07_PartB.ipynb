{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMx5iEvdyC3rXQbh7IT0Rhm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/schumbar/CMPE297/blob/main/assignment_07/ShawnChumbar_Assignment07_PartB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 07 - Advanced Prompt Engineering Strategies\n",
        "## Part B: Write 21 Prompt Templates\n",
        "\n",
        "### Assignment Description\n",
        "\n",
        "Create 21 diverse and practical prompt templates, ensuring a mix of success and failure cases. Present these templates both in a Colab notebook and as a slide deck. Templates should illustrate the following prompt patterns, referencing the resources provided:  \n",
        "\n",
        "- **Input Semantics:** Meta Language Creation  \n",
        "- **Output Customization:** Output Automater, Persona, Visualization Generator, Recipe, Template  \n",
        "- **Error Identification:** Fact Check List, Reflection  \n",
        "- **Prompt Improvement:** Question Refinement, Alternative Approaches, Cognitive Verifier, Refusal Breaker  \n",
        "- **Interaction:** Flipped Interaction, Game Play, Infinite Generation  \n",
        "- **Context Control:** Context Manager  \n",
        "\n",
        "### References\n",
        "1. [Prompting Guide](https://www.promptingguide.ai/papers)\n",
        "2. [Research Paper](https://arxiv.org/pdf/2302.11382.pdf)"
      ],
      "metadata": {
        "id": "hK0k-EHsBdzR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup"
      ],
      "metadata": {
        "id": "ydF7_SdUCWDc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Install Required Packages"
      ],
      "metadata": {
        "id": "QETKpIRBDFF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install openai\n",
        "!pip install langchain\n",
        "!pip install langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUJTxXjHCYM-",
        "outputId": "72ac83d4-91a2-4069-bf53-71bf913b6932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.7)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.2)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.19)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.143)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain) (3.0.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.7-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
            "Collecting SQLAlchemy<2.0.36,>=1.4 (from langchain_community)\n",
            "  Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.11.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.3.7)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.17 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.3.19)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.143)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.7->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.7->langchain_community) (2.9.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<2.0.36,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.17->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.7->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.7->langchain_community) (2.23.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.2.2)\n",
            "Downloading langchain_community-0.3.7-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
            "Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: SQLAlchemy, python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.36\n",
            "    Uninstalling SQLAlchemy-2.0.36:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.36\n",
            "Successfully installed SQLAlchemy-2.0.35 dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain_community-0.3.7 marshmallow-3.23.1 mypy-extensions-1.0.0 pydantic-settings-2.6.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import Necessary Libraries"
      ],
      "metadata": {
        "id": "gHufTK2-DIT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "from langchain_community.llms import OpenAI as LangChainOpenAI\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from typing import List\n",
        "import json\n",
        "import os"
      ],
      "metadata": {
        "id": "abxUC2BKCHXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Set API Keys"
      ],
      "metadata": {
        "id": "KJiJA7MlDMRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "open_ai_api_key = userdata.get('OPENAI_KEY')\n",
        "hugging_face_token = userdata.get('HF_TOKEN')\n",
        "os.environ[\"OPENAI_API_KEY\"] = open_ai_api_key"
      ],
      "metadata": {
        "id": "YAhGQ3bCChRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Initialize Clients"
      ],
      "metadata": {
        "id": "zOSSyY9NDOZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize OpenAI client\n",
        "client = OpenAI(api_key=open_ai_api_key)\n",
        "\n",
        "# Initialize LangChain LLM\n",
        "# llm = LangChainOpenAI(temperature=0)"
      ],
      "metadata": {
        "id": "D2XuDlmnC4gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create Functions to Interact with OpenAI API"
      ],
      "metadata": {
        "id": "_3D1Vx_vDQXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to interact with the OpenAI API\n",
        "def get_response(prompt, model=\"gpt-3.5-turbo\", max_tokens=300):\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=0  # Set temperature to 0 for deterministic output\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()"
      ],
      "metadata": {
        "id": "fyY01Rw8CcJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Zero-Shot Prompting**"
      ],
      "metadata": {
        "id": "PlQ2gfpZDU9a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Success Case"
      ],
      "metadata": {
        "id": "0OV_XmqIE-KC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"### 1. Zero-Shot Prompting ###\")\n",
        "prompt = \"\"\"\n",
        "Answer the following question:\n",
        "\n",
        "What is the capital of Japan?\n",
        "\"\"\"\n",
        "response = get_response(prompt)\n",
        "print(\"Prompt:\", prompt)\n",
        "print(\"Response:\", response)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llvmyC7XE-gf",
        "outputId": "6d4b9156-081a-4b5c-c781-03d2c3b49ff4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### 1. Zero-Shot Prompting ###\n",
            "Prompt: \n",
            "Answer the following question:\n",
            "\n",
            "What is the capital of Japan?\n",
            "\n",
            "Response: The capital of Japan is Tokyo.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Failure Case\n",
        "\n"
      ],
      "metadata": {
        "id": "ddafDGlvE-Hi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_failure = \"\"\"\n",
        "Answer the following question:\n",
        "\n",
        "Who is known as the Father of Computers?\n",
        "\"\"\"\n",
        "response_failure = get_response(prompt_failure)\n",
        "print(\"Prompt (Failure Case):\", prompt_failure)\n",
        "print(\"Response:\", response_failure)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xS3UyaScDbOb",
        "outputId": "567d9f5a-bb7a-4d06-b134-69c7727af41b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt (Failure Case): \n",
            "Answer the following question:\n",
            "\n",
            "Who is known as the Father of Computers?\n",
            "\n",
            "Response: Charles Babbage is known as the Father of Computers.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. One-Shot Prompting**"
      ],
      "metadata": {
        "id": "QCKvQdw-Dblf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Success Case"
      ],
      "metadata": {
        "id": "o6jwhAnmFGYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"### 2. One-Shot Prompting ###\")\n",
        "prompt = \"\"\"\n",
        "Translate the following English sentence to Spanish.\n",
        "\n",
        "English: \"Good morning.\"\n",
        "\n",
        "Spanish: \"Buenos días.\"\n",
        "\n",
        "Now translate this sentence:\n",
        "\n",
        "English: \"Thank you for your help.\"\n",
        "\n",
        "Spanish:\n",
        "\"\"\"\n",
        "response = get_response(prompt)\n",
        "print(\"Prompt:\", prompt)\n",
        "print(\"Response:\", response)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMzonxehFGnc",
        "outputId": "c7dacd26-2a1e-4e69-cf72-d372eb815d05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### 2. One-Shot Prompting ###\n",
            "Prompt: \n",
            "Translate the following English sentence to Spanish.\n",
            "\n",
            "English: \"Good morning.\"\n",
            "\n",
            "Spanish: \"Buenos días.\"\n",
            "\n",
            "Now translate this sentence:\n",
            "\n",
            "English: \"Thank you for your help.\"\n",
            "\n",
            "Spanish:\n",
            "\n",
            "Response: \"Gracias por tu ayuda.\"\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Failure Case"
      ],
      "metadata": {
        "id": "H0rePBcAFG7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Failure Case\n",
        "prompt_failure = \"\"\"\n",
        "Translate the following English sentence to Spanish.\n",
        "\n",
        "English: \"Good morning.\"\n",
        "\n",
        "Spanish: \"Buenos días.\"\n",
        "\n",
        "Now translate this sentence:\n",
        "\n",
        "English: \"Thank you for your help.\"\n",
        "\n",
        "Spanish:\n",
        "\"\"\"\n",
        "response_failure = get_response(prompt_failure)\n",
        "print(\"Prompt (Failure Case):\", prompt_failure)\n",
        "print(\"Response:\", response_failure)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cS4Id2OnDckV",
        "outputId": "31c4a792-4f23-4352-dcf7-bf519ff04d12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt (Failure Case): \n",
            "Translate the following English sentence to Spanish.\n",
            "\n",
            "English: \"Good morning.\"\n",
            "\n",
            "Spanish: \"Buenos días.\"\n",
            "\n",
            "Now translate this sentence:\n",
            "\n",
            "English: \"Thank you for your help.\"\n",
            "\n",
            "Spanish:\n",
            "\n",
            "Response: \"Gracias por tu ayuda.\"\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. Few-Shot Prompting**"
      ],
      "metadata": {
        "id": "nXk1M0jYFMmB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Success Case"
      ],
      "metadata": {
        "id": "ckdxd0LFFRmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Few-Shot Prompting\n",
        "print(\"### 3. Few-Shot Prompting ###\")\n",
        "prompt = \"\"\"\n",
        "Identify the animal based on the sound.\n",
        "\n",
        "Example:\n",
        "\n",
        "Sound: \"Meow\"\n",
        "\n",
        "Animal: \"Cat\"\n",
        "\n",
        "Sound: \"Bark\"\n",
        "\n",
        "Animal: \"Dog\"\n",
        "\n",
        "Now:\n",
        "\n",
        "Sound: \"Neigh\"\n",
        "\n",
        "Animal:\n",
        "\"\"\"\n",
        "response = get_response(prompt)\n",
        "print(\"Prompt:\", prompt)\n",
        "print(\"Response:\", response)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LohRyuRkFS2b",
        "outputId": "107b73df-598f-406e-8367-925894987466"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### 3. Few-Shot Prompting ###\n",
            "Prompt: \n",
            "Identify the animal based on the sound.\n",
            "\n",
            "Example:\n",
            "\n",
            "Sound: \"Meow\"\n",
            "\n",
            "Animal: \"Cat\"\n",
            "\n",
            "Sound: \"Bark\"\n",
            "\n",
            "Animal: \"Dog\"\n",
            "\n",
            "Now:\n",
            "\n",
            "Sound: \"Neigh\"\n",
            "\n",
            "Animal:\n",
            "\n",
            "Response: Horse\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Failure Case"
      ],
      "metadata": {
        "id": "pcGAD0nUFTKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Failure Case\n",
        "prompt_failure = \"\"\"\n",
        "Identify the animal based on the sound.\n",
        "\n",
        "Example:\n",
        "\n",
        "Sound: \"Meow\"\n",
        "\n",
        "Animal: \"Cat\"\n",
        "\n",
        "Sound: \"Bark\"\n",
        "\n",
        "Animal: \"Dog\"\n",
        "\n",
        "Now:\n",
        "\n",
        "Sound: \"Neigh\"\n",
        "\n",
        "Animal:\n",
        "\"\"\"\n",
        "response_failure = get_response(prompt_failure)\n",
        "print(\"Prompt (Failure Case):\", prompt_failure)\n",
        "print(\"Response:\", response_failure)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0lDk2yLDfDX",
        "outputId": "2b780273-00fa-4a81-c4b6-b188f6b35dcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt (Failure Case): \n",
            "Identify the animal based on the sound.\n",
            "\n",
            "Example:\n",
            "\n",
            "Sound: \"Meow\"\n",
            "\n",
            "Animal: \"Cat\"\n",
            "\n",
            "Sound: \"Bark\"\n",
            "\n",
            "Animal: \"Dog\"\n",
            "\n",
            "Now:\n",
            "\n",
            "Sound: \"Neigh\"\n",
            "\n",
            "Animal:\n",
            "\n",
            "Response: Horse\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. Chain-of-Thought Prompting**"
      ],
      "metadata": {
        "id": "lq1eeOn_FW8P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Success Case"
      ],
      "metadata": {
        "id": "p-NYCbVoFaLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Chain-of-Thought Prompting\n",
        "print(\"### 4. Chain-of-Thought Prompting ###\")\n",
        "prompt = \"\"\"Solve the math problem step-by-step:\n",
        "\n",
        "If a train travels at 60 mph for 2 hours, how far does it go?\n",
        "\n",
        "Solution:\n",
        "\"\"\"\n",
        "response = get_response(prompt)\n",
        "print(\"Prompt:\", prompt)\n",
        "print(\"Response:\", response)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbLXe3KaFZj-",
        "outputId": "14915637-566d-4de7-e9e3-d43e388342df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### 4. Chain-of-Thought Prompting ###\n",
            "Prompt: Solve the math problem step-by-step:\n",
            "\n",
            "If a train travels at 60 mph for 2 hours, how far does it go?\n",
            "\n",
            "Solution:\n",
            "\n",
            "Response: To find the distance the train travels, we can use the formula:\n",
            "\n",
            "Distance = Speed x Time\n",
            "\n",
            "Given that the train travels at 60 mph for 2 hours, we can plug in the values:\n",
            "\n",
            "Distance = 60 mph x 2 hours\n",
            "Distance = 120 miles\n",
            "\n",
            "Therefore, the train travels 120 miles in 2 hours at a speed of 60 mph.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Failure Case"
      ],
      "metadata": {
        "id": "dafeaOXMFbFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Failure Case: Incorrect calculation without steps\n",
        "prompt_failure = \"\"\"Solve the math problem step-by-step:\n",
        "\n",
        "If a car travels at 50 mph for 1.5 hours, how far does it go?\n",
        "\n",
        "Solution:\n",
        "\"\"\"\n",
        "response_failure = get_response(prompt_failure)\n",
        "print(\"Prompt (Failure Case):\", prompt_failure)\n",
        "print(\"Response:\", response_failure)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9Bqx8N6FdHc",
        "outputId": "ead3975a-8125-4ef3-97b4-c590159677ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt (Failure Case): Solve the math problem step-by-step:\n",
            "\n",
            "If a car travels at 50 mph for 1.5 hours, how far does it go?\n",
            "\n",
            "Solution:\n",
            "\n",
            "Response: To find the distance the car travels, we can use the formula:\n",
            "\n",
            "Distance = Speed x Time\n",
            "\n",
            "Given that the car travels at 50 mph for 1.5 hours, we can plug in the values:\n",
            "\n",
            "Distance = 50 mph x 1.5 hours\n",
            "Distance = 75 miles\n",
            "\n",
            "Therefore, the car travels 75 miles.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5. Instruction Following**"
      ],
      "metadata": {
        "id": "skZI6VKtFfBh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Success Case"
      ],
      "metadata": {
        "id": "3rDTadvpFhVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Instruction Following\n",
        "print(\"### 5. Instruction Following ###\")\n",
        "prompt = \"\"\"Please provide a summary of the following text in no more than 50 words.\n",
        "\n",
        "Text: \"Artificial intelligence is a branch of computer science that aims to create intelligent machines. It has become an essential part of the technology industry.\"\n",
        "\"\"\"\n",
        "response = get_response(prompt)\n",
        "print(\"Prompt:\", prompt)\n",
        "print(\"Response:\", response)\n",
        "print(\"Word Count:\", len(response.split()))\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0IJW9rJFhn-",
        "outputId": "9f9d0ec6-4225-4084-a0ee-b06ba397194d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### 5. Instruction Following ###\n",
            "Prompt: Please provide a summary of the following text in no more than 50 words.\n",
            "\n",
            "Text: \"Artificial intelligence is a branch of computer science that aims to create intelligent machines. It has become an essential part of the technology industry.\"\n",
            "\n",
            "Response: Artificial intelligence is a field in computer science focused on developing intelligent machines, now integral to the technology sector.\n",
            "Word Count: 19\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Failure Case"
      ],
      "metadata": {
        "id": "plBmuygYFh8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Failure Case: Summary exceeds 50 words\n",
        "prompt_failure = \"\"\"Please provide a summary of the following text in no more than 50 words.\n",
        "\n",
        "Text: \"Machine learning is a subset of artificial intelligence that involves the study of algorithms and statistical models that computer systems use to perform tasks without explicit instructions, relying on patterns and inference instead.\"\n",
        "\"\"\"\n",
        "response_failure = get_response(prompt_failure)\n",
        "print(\"Prompt (Failure Case):\", prompt_failure)\n",
        "print(\"Response:\", response_failure)\n",
        "print(\"Word Count:\", len(response_failure.split()))\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keorzsRsEIL3",
        "outputId": "bb23f88e-2603-4524-804c-7f671841a5f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt (Failure Case): Please provide a summary of the following text in no more than 50 words.\n",
            "\n",
            "Text: \"Machine learning is a subset of artificial intelligence that involves the study of algorithms and statistical models that computer systems use to perform tasks without explicit instructions, relying on patterns and inference instead.\"\n",
            "\n",
            "Response: Machine learning is a branch of artificial intelligence that focuses on algorithms and statistical models for computer systems to perform tasks without direct instructions, relying on patterns and inference.\n",
            "Word Count: 29\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6. Roleplaying**"
      ],
      "metadata": {
        "id": "dLS9B1riFm_0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Success Case"
      ],
      "metadata": {
        "id": "Cs4q4DAsFpRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Roleplaying\n",
        "print(\"### 6. Roleplaying ###\")\n",
        "prompt = \"\"\"You are a fitness coach. Provide advice on:\n",
        "\n",
        "How can I improve my cardiovascular health?\n",
        "\"\"\"\n",
        "response = get_response(prompt)\n",
        "print(\"Prompt:\", prompt)\n",
        "print(\"Response:\", response)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFoFBKoNFrXz",
        "outputId": "cc080b9a-c0b1-4c1d-bfff-4c81b8d7ac3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### 6. Roleplaying ###\n",
            "Prompt: You are a fitness coach. Provide advice on:\n",
            "\n",
            "How can I improve my cardiovascular health?\n",
            "\n",
            "Response: Improving your cardiovascular health is crucial for overall well-being and longevity. Here are some tips to help you achieve better cardiovascular fitness:\n",
            "\n",
            "1. Start with regular aerobic exercise: Engage in activities that elevate your heart rate, such as running, cycling, swimming, or brisk walking. Aim for at least 150 minutes of moderate-intensity aerobic exercise per week.\n",
            "\n",
            "2. Incorporate high-intensity interval training (HIIT): HIIT involves short bursts of intense exercise followed by brief periods of rest or lower-intensity activity. This type of training has been shown to improve cardiovascular fitness more effectively than steady-state cardio.\n",
            "\n",
            "3. Strength training: Building muscle can also benefit your cardiovascular health. Include strength training exercises in your routine to improve your overall fitness level.\n",
            "\n",
            "4. Maintain a healthy diet: Eating a balanced diet rich in fruits, vegetables, whole grains, lean proteins, and healthy fats can help support your cardiovascular health. Limit your intake of processed foods, sugary drinks, and saturated fats.\n",
            "\n",
            "5. Stay hydrated: Proper hydration is essential for cardiovascular health. Drink plenty of water throughout the day to support your heart and overall health.\n",
            "\n",
            "6. Get enough sleep: Adequate rest is crucial for your cardiovascular health. Aim for 7-9 hours of quality sleep each night to allow your body to recover and recharge.\n",
            "\n",
            "7. Manage stress: Chronic stress can have a negative impact on your heart health. Practice stress-reducing techniques such as meditation, deep breathing, yoga, or spending time in\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Failure Case"
      ],
      "metadata": {
        "id": "gr39PUg0FqlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Failure Case: Off-topic response\n",
        "prompt_failure = \"\"\"You are a fitness coach. Provide advice on:\n",
        "\n",
        "How can I improve my cardiovascular health?\n",
        "\"\"\"\n",
        "response_failure = get_response(prompt_failure)\n",
        "print(\"Prompt (Failure Case):\", prompt_failure)\n",
        "print(\"Response:\", response_failure)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsWQfVAjEJxA",
        "outputId": "680b8357-9d73-4002-f410-9461d5f342a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt (Failure Case): You are a fitness coach. Provide advice on:\n",
            "\n",
            "How can I improve my cardiovascular health?\n",
            "\n",
            "Response: Improving your cardiovascular health is essential for overall well-being and longevity. Here are some tips to help you achieve better cardiovascular fitness:\n",
            "\n",
            "1. Engage in regular aerobic exercise: Aim for at least 150 minutes of moderate-intensity aerobic exercise per week, such as brisk walking, running, cycling, or swimming. This will help strengthen your heart and improve circulation.\n",
            "\n",
            "2. Incorporate high-intensity interval training (HIIT): HIIT workouts involve short bursts of intense exercise followed by brief periods of rest. This type of training has been shown to be very effective in improving cardiovascular fitness.\n",
            "\n",
            "3. Maintain a healthy diet: Eat a balanced diet rich in fruits, vegetables, whole grains, lean proteins, and healthy fats. Limit your intake of processed foods, sugary drinks, and saturated fats, which can contribute to heart disease.\n",
            "\n",
            "4. Quit smoking: Smoking is a major risk factor for heart disease and other cardiovascular problems. If you smoke, seek help to quit and improve your heart health.\n",
            "\n",
            "5. Manage stress: Chronic stress can have a negative impact on your heart health. Practice stress-reducing techniques such as meditation, yoga, deep breathing exercises, or spending time in nature.\n",
            "\n",
            "6. Get enough sleep: Aim for 7-9 hours of quality sleep each night. Poor sleep can contribute to high blood pressure, obesity, and other risk factors for heart disease.\n",
            "\n",
            "7. Monitor your heart health: Regularly check your blood pressure, cholesterol levels, and overall heart health with your\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7. Data Augmentation**"
      ],
      "metadata": {
        "id": "i1triVcyGDgy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Success Case"
      ],
      "metadata": {
        "id": "GrO560izGFkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Data Augmentation\n",
        "print(\"### 7. Data Augmentation ###\")\n",
        "prompt = \"\"\"Generate synonyms for the word \"happy\".\n",
        "\n",
        "Synonyms:\n",
        "\"\"\"\n",
        "response = get_response(prompt)\n",
        "print(\"Prompt:\", prompt)\n",
        "print(\"Response:\", response)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5odNmcGGHGU",
        "outputId": "7941b78b-e4bd-4360-e9b5-ffc1cdf3016c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### 7. Data Augmentation ###\n",
            "Prompt: Generate synonyms for the word \"happy\".\n",
            "\n",
            "Synonyms:\n",
            "\n",
            "Response: joyful, content, delighted, pleased, cheerful, ecstatic, elated, jubilant, satisfied, blissful, euphoric, overjoyed, thrilled, merry, glad\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Failure Case"
      ],
      "metadata": {
        "id": "WPTr_wBBGHZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Failure Case: Provides antonyms instead of synonyms\n",
        "prompt_failure = \"\"\"Generate synonyms for the word \"sad\".\n",
        "\n",
        "Synonyms:\n",
        "\"\"\"\n",
        "response_failure = get_response(prompt_failure)\n",
        "print(\"Prompt (Failure Case):\", prompt_failure)\n",
        "print(\"Response:\", response_failure)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "389ix2a2EKTI",
        "outputId": "7cb418ee-f957-455c-925c-494eac5715f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt (Failure Case): Generate synonyms for the word \"sad\".\n",
            "\n",
            "Synonyms:\n",
            "\n",
            "Response: 1. Unhappy\n",
            "2. Sorrowful\n",
            "3. Mournful\n",
            "4. Melancholy\n",
            "5. Gloomy\n",
            "6. Despondent\n",
            "7. Dejected\n",
            "8. Depressed\n",
            "9. Dismal\n",
            "10. Blue\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **8. Style Transfer**\n"
      ],
      "metadata": {
        "id": "UgGJHU_HGJkJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Success Case"
      ],
      "metadata": {
        "id": "R7hQ06gxGMOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Style Transfer\n",
        "print(\"### 8. Style Transfer ###\")\n",
        "prompt = \"\"\"Rewrite the following sentence in a formal tone:\n",
        "\n",
        "\"Can you fix this issue ASAP?\"\n",
        "\"\"\"\n",
        "response = get_response(prompt)\n",
        "print(\"Prompt:\", prompt)\n",
        "print(\"Response:\", response)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5iaEL7HGN_A",
        "outputId": "2f389f46-4bf1-424c-a798-88699674758f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### 8. Style Transfer ###\n",
            "Prompt: Rewrite the following sentence in a formal tone:\n",
            "\n",
            "\"Can you fix this issue ASAP?\"\n",
            "\n",
            "Response: Could you please address this issue as soon as possible?\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Failure Case"
      ],
      "metadata": {
        "id": "tmDaAsAeGNVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Failure Case: Tone remains informal\n",
        "prompt_failure = \"\"\"Rewrite the following sentence in a formal tone:\n",
        "\n",
        "\"Hey, what's up?\"\n",
        "\"\"\"\n",
        "response_failure = get_response(prompt_failure)\n",
        "print(\"Prompt (Failure Case):\", prompt_failure)\n",
        "print(\"Response:\", response_failure)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yazDPin0EMzo",
        "outputId": "e32659ad-3d25-4ed8-fe86-1ef95361f3b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt (Failure Case): Rewrite the following sentence in a formal tone:\n",
            "\n",
            "\"Hey, what's up?\"\n",
            "\n",
            "Response: Hello, how are you?\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **9. Using Delimiters to Specify Context**"
      ],
      "metadata": {
        "id": "aJq9nt65GP1a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Success Case"
      ],
      "metadata": {
        "id": "P0mdxoMZGRW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Using Delimiters to Specify Context\n",
        "print(\"### 9. Using Delimiters to Specify Context ###\")\n",
        "prompt = \"\"\"Extract the names of all people mentioned in the following text delimited by triple dashes:\n",
        "\n",
        "---\n",
        "\n",
        "Alice and Bob went to the market where they met Charlie.\n",
        "\n",
        "---\n",
        "\n",
        "Names:\n",
        "\"\"\"\n",
        "response = get_response(prompt)\n",
        "print(\"Prompt:\", prompt)\n",
        "print(\"Response:\", response)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KhqZG94GSLa",
        "outputId": "b90cf254-03c3-4a0f-8080-7d8a3317ab4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### 9. Using Delimiters to Specify Context ###\n",
            "Prompt: Extract the names of all people mentioned in the following text delimited by triple dashes:\n",
            "\n",
            "---\n",
            "\n",
            "Alice and Bob went to the market where they met Charlie.\n",
            "\n",
            "---\n",
            "\n",
            "Names:\n",
            "\n",
            "Response: Alice\n",
            "Bob\n",
            "Charlie\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Failure Case"
      ],
      "metadata": {
        "id": "oLLLPtOiGSd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Failure Case: Includes non-names\n",
        "prompt_failure = \"\"\"Extract the names of all people mentioned in the following text delimited by triple dashes:\n",
        "\n",
        "---\n",
        "\n",
        "Tom and Jerry visited the Grand Canyon.\n",
        "\n",
        "---\n",
        "\n",
        "Names:\n",
        "\"\"\"\n",
        "response_failure = get_response(prompt_failure)\n",
        "print(\"Prompt (Failure Case):\", prompt_failure)\n",
        "print(\"Response:\", response_failure)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpH95vnJENIR",
        "outputId": "a20d0e57-b5d8-48e8-d955-9dd765ba4c73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt (Failure Case): Extract the names of all people mentioned in the following text delimited by triple dashes:\n",
            "\n",
            "---\n",
            "\n",
            "Tom and Jerry visited the Grand Canyon.\n",
            "\n",
            "---\n",
            "\n",
            "Names:\n",
            "\n",
            "Response: Tom\n",
            "Jerry\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **10. Providing Examples in Context**"
      ],
      "metadata": {
        "id": "m_YEkv4jGXaJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Success Case"
      ],
      "metadata": {
        "id": "3mbG9AqGGYl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Providing Examples in Context\n",
        "print(\"### 10. Providing Examples in Context ###\")\n",
        "prompt = \"\"\"Determine if the following statements are true or false.\n",
        "\n",
        "Examples:\n",
        "\n",
        "Statement: \"The sky is blue.\" - True\n",
        "\n",
        "Statement: \"Fish can fly.\" - False\n",
        "\n",
        "Now evaluate:\n",
        "\n",
        "Statement: \"Humans need oxygen to survive.\" -\n",
        "\"\"\"\n",
        "response = get_response(prompt)\n",
        "print(\"Prompt:\", prompt)\n",
        "print(\"Response:\", response)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgoyPA65GYNm",
        "outputId": "712a0a1d-23ec-4130-f408-1d70af3b0e2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### 10. Providing Examples in Context ###\n",
            "Prompt: Determine if the following statements are true or false.\n",
            "\n",
            "Examples:\n",
            "\n",
            "Statement: \"The sky is blue.\" - True\n",
            "\n",
            "Statement: \"Fish can fly.\" - False\n",
            "\n",
            "Now evaluate:\n",
            "\n",
            "Statement: \"Humans need oxygen to survive.\" -\n",
            "\n",
            "Response: True\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Failure Case"
      ],
      "metadata": {
        "id": "74j2vizKGYZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Failure Case: Incorrect evaluation\n",
        "prompt_failure = \"\"\"Determine if the following statements are true or false.\n",
        "\n",
        "Examples:\n",
        "\n",
        "Statement: \"The sky is blue.\" - True\n",
        "\n",
        "Statement: \"Fish can fly.\" - False\n",
        "\n",
        "Now evaluate:\n",
        "\n",
        "Statement: \"The moon is made of cheese.\" -\n",
        "\"\"\"\n",
        "response_failure = get_response(prompt_failure)\n",
        "print(\"Prompt (Failure Case):\", prompt_failure)\n",
        "print(\"Response:\", response_failure)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1fForf2EPMC",
        "outputId": "dc0b2c81-c7b8-4dc5-d624-196908e02d09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt (Failure Case): Determine if the following statements are true or false.\n",
            "\n",
            "Examples:\n",
            "\n",
            "Statement: \"The sky is blue.\" - True\n",
            "\n",
            "Statement: \"Fish can fly.\" - False\n",
            "\n",
            "Now evaluate:\n",
            "\n",
            "Statement: \"The moon is made of cheese.\" -\n",
            "\n",
            "Response: False\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **11. Providing Reasoning Steps**"
      ],
      "metadata": {
        "id": "m2zGhJQPGdbb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Success Case"
      ],
      "metadata": {
        "id": "4vL_V9J6Ge5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Providing Reasoning Steps\n",
        "print(\"### 11. Providing Reasoning Steps ###\")\n",
        "prompt = \"\"\"Is the number 17 prime? Explain your reasoning.\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "response = get_response(prompt)\n",
        "print(\"Prompt:\", prompt)\n",
        "print(\"Response:\", response)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4UcUNEFGeH-",
        "outputId": "ca0feda5-a8de-4ad5-c96d-a9e511ab5f1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### 11. Providing Reasoning Steps ###\n",
            "Prompt: Is the number 17 prime? Explain your reasoning.\n",
            "\n",
            "Answer:\n",
            "\n",
            "Response: Yes, the number 17 is prime because it is only divisible by 1 and itself. There are no other whole numbers that can divide evenly into 17, making it a prime number.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Failure Case"
      ],
      "metadata": {
        "id": "Xe7Lwmn2Gf1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Failure Case: Does not provide reasoning\n",
        "prompt_failure = \"\"\"Is the number 16 prime? Explain your reasoning.\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "response_failure = get_response(prompt_failure)\n",
        "print(\"Prompt (Failure Case):\", prompt_failure)\n",
        "print(\"Response:\", response_failure)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpbffKn9ESP1",
        "outputId": "c2424345-7a81-42a3-9194-703af85c5b14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt (Failure Case): Is the number 16 prime? Explain your reasoning.\n",
            "\n",
            "Answer:\n",
            "\n",
            "Response: No, the number 16 is not prime because it can be divided evenly by numbers other than 1 and itself. In this case, 16 can be divided by 2, 4, 8, and 16. Since prime numbers can only be divided by 1 and themselves, 16 does not meet this criteria and is therefore not a prime number.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **12. Using Conditional Statements**"
      ],
      "metadata": {
        "id": "vCtIUW1qGid4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Success Case"
      ],
      "metadata": {
        "id": "1wJex_MLGkri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. Using Conditional Statements\n",
        "print(\"### 12. Using Conditional Statements ###\")\n",
        "prompt = \"\"\"If the weather is \"sunny\", then suggest an activity.\n",
        "\n",
        "Weather: \"sunny\"\n",
        "\n",
        "Suggestion:\n",
        "\"\"\"\n",
        "response = get_response(prompt)\n",
        "print(\"Prompt:\", prompt)\n",
        "print(\"Response:\", response)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYKzpIUxGk5y",
        "outputId": "b3b125ed-23c7-4075-f2ab-b6a0294f3414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### 12. Using Conditional Statements ###\n",
            "Prompt: If the weather is \"sunny\", then suggest an activity.\n",
            "\n",
            "Weather: \"sunny\"\n",
            "\n",
            "Suggestion:\n",
            "\n",
            "Response: Go for a hike or picnic in the park.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Failure Case"
      ],
      "metadata": {
        "id": "tnKTBqiXGmIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Failure Case: Suggestion doesn't match the condition\n",
        "prompt_failure = \"\"\"If the weather is \"rainy\", then suggest an activity.\n",
        "\n",
        "Weather: \"rainy\"\n",
        "\n",
        "Suggestion:\n",
        "\"\"\"\n",
        "response_failure = get_response(prompt_failure)\n",
        "print(\"Prompt (Failure Case):\", prompt_failure)\n",
        "print(\"Response:\", response_failure)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dntxh8vaETtG",
        "outputId": "a02e4357-67c6-4d53-8fb0-8d4456d03d8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt (Failure Case): If the weather is \"rainy\", then suggest an activity.\n",
            "\n",
            "Weather: \"rainy\"\n",
            "\n",
            "Suggestion:\n",
            "\n",
            "Response: Stay indoors and have a movie marathon with some popcorn and hot chocolate.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **13. Multi-turn Dialogues**"
      ],
      "metadata": {
        "id": "Ra91k0u0GpwR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Success Case"
      ],
      "metadata": {
        "id": "OHMhpbF0GqXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 13. Multi-turn Dialogues\n",
        "print(\"### 13. Multi-turn Dialogues ###\")\n",
        "prompt = \"\"\"User: \"What's the weather like today?\"\n",
        "\n",
        "Assistant:\n",
        "\"\"\"\n",
        "response = get_response(prompt)\n",
        "print(\"Prompt:\", prompt)\n",
        "print(\"Response:\", response)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihzMXDcZGtO1",
        "outputId": "6a461497-7987-470e-f203-7eb1fff8e332"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### 13. Multi-turn Dialogues ###\n",
            "Prompt: User: \"What's the weather like today?\"\n",
            "\n",
            "Assistant:\n",
            "\n",
            "Response: I'm sorry, I don't have access to real-time weather information. You can check your local weather forecast on a weather website or app for the most up-to-date information.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Failure Case"
      ],
      "metadata": {
        "id": "Vh2r_XfEGrFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Failure Case: Provides real-time data inaccurately\n",
        "prompt_failure = \"\"\"User: \"What time is it now?\"\n",
        "\n",
        "Assistant:\n",
        "\"\"\"\n",
        "response_failure = get_response(prompt_failure)\n",
        "print(\"Prompt (Failure Case):\", prompt_failure)\n",
        "print(\"Response:\", response_failure)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xB2_zU6EVA2",
        "outputId": "d52412fb-f206-4d5c-8baa-a3074ac20903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt (Failure Case): User: \"What time is it now?\"\n",
            "\n",
            "Assistant:\n",
            "\n",
            "Response: I'm sorry, I am not able to provide real-time information such as the current time.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **14. Prompting for Code Generation**"
      ],
      "metadata": {
        "id": "6cFVMARLGx6U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Success Case"
      ],
      "metadata": {
        "id": "vr_jfIGxGySY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 14. Prompting for Code Generation\n",
        "print(\"### 14. Prompting for Code Generation ###\")\n",
        "prompt = \"\"\"Write a function in Python that checks if a number is even or odd.\n",
        "\n",
        "Function:\n",
        "\"\"\"\n",
        "response = get_response(prompt)\n",
        "print(\"Prompt:\", prompt)\n",
        "print(\"Response:\", response)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vM9oqOxCGz1N",
        "outputId": "0bafe94b-15f6-4acb-cdd6-b885750af3f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### 14. Prompting for Code Generation ###\n",
            "Prompt: Write a function in Python that checks if a number is even or odd.\n",
            "\n",
            "Function:\n",
            "\n",
            "Response: def check_even_odd(num):\n",
            "    if num % 2 == 0:\n",
            "        return \"Even\"\n",
            "    else:\n",
            "        return \"Odd\"\n",
            "\n",
            "# Test the function\n",
            "print(check_even_odd(5))  # Output: Odd\n",
            "print(check_even_odd(10))  # Output: Even\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Failure Case"
      ],
      "metadata": {
        "id": "TjBQEoyiGzBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Failure Case: Syntax error in code\n",
        "prompt_failure = \"\"\"Write a function in Python that calculates the factorial of a number.\n",
        "\n",
        "Function:\n",
        "\"\"\"\n",
        "response_failure = get_response(prompt_failure)\n",
        "print(\"Prompt (Failure Case):\", prompt_failure)\n",
        "print(\"Response:\", response_failure)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vxuWgjaEWcE",
        "outputId": "983dd103-8668-41d3-bf8b-7ccbc320c66c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt (Failure Case): Write a function in Python that calculates the factorial of a number.\n",
            "\n",
            "Function:\n",
            "\n",
            "Response: def factorial(n):\n",
            "    if n == 0:\n",
            "        return 1\n",
            "    else:\n",
            "        return n * factorial(n-1)\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **15. Prompting for Translation**"
      ],
      "metadata": {
        "id": "TSM778CwG2Q4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Success Case"
      ],
      "metadata": {
        "id": "oV9SkpSoG4sr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 15. Prompting for Translation\n",
        "print(\"### 15. Prompting for Translation ###\")\n",
        "prompt = \"\"\"Translate the following sentence to French:\n",
        "\n",
        "\"I would like a cup of coffee.\"\n",
        "\"\"\"\n",
        "response = get_response(prompt)\n",
        "print(\"Prompt:\", prompt)\n",
        "print(\"Response:\", response)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7-zSWb5G4JC",
        "outputId": "caa75d95-3df8-4286-c075-2793606e0332"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### 15. Prompting for Translation ###\n",
            "Prompt: Translate the following sentence to French:\n",
            "\n",
            "\"I would like a cup of coffee.\"\n",
            "\n",
            "Response: \"Je voudrais une tasse de café.\"\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Failure Case"
      ],
      "metadata": {
        "id": "6QKHP4j7G4Xs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Failure Case: Translates into the wrong language\n",
        "prompt_failure = \"\"\"Translate the following sentence to French:\n",
        "\n",
        "\"Where is the nearest train station?\"\n",
        "\"\"\"\n",
        "response_failure = get_response(prompt_failure)\n",
        "print(\"Prompt (Failure Case):\", prompt_failure)\n",
        "print(\"Response:\", response_failure)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91OJJ-SSEX44",
        "outputId": "79060c9c-b6d2-4d22-8e7d-cefc1da430c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt (Failure Case): Translate the following sentence to French:\n",
            "\n",
            "\"Where is the nearest train station?\"\n",
            "\n",
            "Response: Où se trouve la gare la plus proche ?\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **16. Prompting for Summarization**"
      ],
      "metadata": {
        "id": "_Hsgo2wgG9DL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Success Case"
      ],
      "metadata": {
        "id": "-8QV39vuG_Yh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 16. Prompting for Summarization\n",
        "print(\"### 16. Prompting for Summarization ###\")\n",
        "prompt = \"\"\"Summarize the main idea of the following paragraph:\n",
        "\n",
        "\"Electric cars are becoming increasingly popular due to their environmental benefits and advancements in technology that have made them more affordable.\"\n",
        "\"\"\"\n",
        "response = get_response(prompt)\n",
        "print(\"Prompt:\", prompt)\n",
        "print(\"Response:\", response)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8TqDgxtG-6t",
        "outputId": "3f554f48-bf91-4b27-cf92-676f666b3cdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### 16. Prompting for Summarization ###\n",
            "Prompt: Summarize the main idea of the following paragraph:\n",
            "\n",
            "\"Electric cars are becoming increasingly popular due to their environmental benefits and advancements in technology that have made them more affordable.\"\n",
            "\n",
            "Response: Electric cars are gaining popularity because of their positive impact on the environment and recent advancements that have made them more cost-effective.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Failure Case"
      ],
      "metadata": {
        "id": "hNSeVj2hG_sV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Failure Case: Off-topic summary\n",
        "prompt_failure = \"\"\"Summarize the main idea of the following paragraph:\n",
        "\n",
        "\"Photosynthesis is the process by which green plants and some other organisms use sunlight to synthesize foods from carbon dioxide and water.\"\n",
        "\"\"\"\n",
        "response_failure = get_response(prompt_failure)\n",
        "print(\"Prompt (Failure Case):\", prompt_failure)\n",
        "print(\"Response:\", response_failure)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIbqjuIqEZfV",
        "outputId": "d68d9536-68ba-4786-eb2f-b6f68283026b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt (Failure Case): Summarize the main idea of the following paragraph:\n",
            "\n",
            "\"Photosynthesis is the process by which green plants and some other organisms use sunlight to synthesize foods from carbon dioxide and water.\"\n",
            "\n",
            "Response: Photosynthesis is a process in which green plants and other organisms use sunlight to create food from carbon dioxide and water.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **17. Prompting for Classification**"
      ],
      "metadata": {
        "id": "30KyBFtYHF7m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Success Case"
      ],
      "metadata": {
        "id": "rVusy-eAHHpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 17. Prompting for Classification\n",
        "print(\"### 17. Prompting for Classification ###\")\n",
        "prompt = \"\"\"Determine whether the sentiment of the following review is Positive, Negative, or Neutral.\n",
        "\n",
        "Review: \"The movie was fantastic! I loved every minute of it.\"\n",
        "\n",
        "Sentiment:\n",
        "\"\"\"\n",
        "response = get_response(prompt)\n",
        "print(\"Prompt:\", prompt)\n",
        "print(\"Response:\", response)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVyMMSGfHK6B",
        "outputId": "5ad085d1-a90b-4f70-849b-01340e54acc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### 17. Prompting for Classification ###\n",
            "Prompt: Determine whether the sentiment of the following review is Positive, Negative, or Neutral.\n",
            "\n",
            "Review: \"The movie was fantastic! I loved every minute of it.\"\n",
            "\n",
            "Sentiment:\n",
            "\n",
            "Response: Positive\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Failure Case"
      ],
      "metadata": {
        "id": "8kp-bP8zHI3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Failure Case: Incorrect sentiment classification\n",
        "prompt_failure = \"\"\"Determine whether the sentiment of the following review is Positive, Negative, or Neutral.\n",
        "\n",
        "Review: \"I was not impressed by the performance.\"\n",
        "\n",
        "Sentiment:\n",
        "\"\"\"\n",
        "response_failure = get_response(prompt_failure)\n",
        "print(\"Prompt (Failure Case):\", prompt_failure)\n",
        "print(\"Response:\", response_failure)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wA1umGu9EbE7",
        "outputId": "65368fc6-5ca9-4073-d0b8-f1d1e0eddd54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt (Failure Case): Determine whether the sentiment of the following review is Positive, Negative, or Neutral.\n",
            "\n",
            "Review: \"I was not impressed by the performance.\"\n",
            "\n",
            "Sentiment:\n",
            "\n",
            "Response: Negative\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **18. Prompting for Question Answering**"
      ],
      "metadata": {
        "id": "soLmoRw9HMB2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Success Case"
      ],
      "metadata": {
        "id": "O9tSGWycHOec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 18. Prompting for Question Answering\n",
        "print(\"### 18. Prompting for Question Answering ###\")\n",
        "prompt = \"\"\"Answer the following question based on the given context.\n",
        "\n",
        "Context: \"The Amazon rainforest is the largest tropical rainforest in the world, known for its biodiversity.\"\n",
        "\n",
        "Question: \"What is the largest tropical rainforest in the world?\"\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "response = get_response(prompt)\n",
        "print(\"Prompt:\", prompt)\n",
        "print(\"Response:\", response)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIUlCyg9HNYa",
        "outputId": "05b1e7fe-0c95-4a7d-f84f-faa62ec57d53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### 18. Prompting for Question Answering ###\n",
            "Prompt: Answer the following question based on the given context.\n",
            "\n",
            "Context: \"The Amazon rainforest is the largest tropical rainforest in the world, known for its biodiversity.\"\n",
            "\n",
            "Question: \"What is the largest tropical rainforest in the world?\"\n",
            "\n",
            "Answer:\n",
            "\n",
            "Response: The Amazon rainforest.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Failure Case"
      ],
      "metadata": {
        "id": "260mJQ3uHPYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Failure Case: Provides an answer not in the context\n",
        "prompt_failure = \"\"\"Answer the following question based on the given context.\n",
        "\n",
        "Context: \"Mount Everest is the highest mountain above sea level, located in the Himalayas.\"\n",
        "\n",
        "Question: \"Where is the Sahara Desert located?\"\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "response_failure = get_response(prompt_failure)\n",
        "print(\"Prompt (Failure Case):\", prompt_failure)\n",
        "print(\"Response:\", response_failure)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpVboa0oEbrW",
        "outputId": "5116f6a8-0fa5-4ab4-8427-d61a1d91d6c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt (Failure Case): Answer the following question based on the given context.\n",
            "\n",
            "Context: \"Mount Everest is the highest mountain above sea level, located in the Himalayas.\"\n",
            "\n",
            "Question: \"Where is the Sahara Desert located?\"\n",
            "\n",
            "Answer:\n",
            "\n",
            "Response: The Sahara Desert is located in North Africa.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **19. Prompting for Creativity**"
      ],
      "metadata": {
        "id": "uWm4CNlLHRWe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Success Case"
      ],
      "metadata": {
        "id": "bvJQMMx3HTEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 19. Prompting for Creativity\n",
        "print(\"### 19. Prompting for Creativity ###\")\n",
        "prompt = \"\"\"Compose a poem about time in the style of Emily Dickinson.\n",
        "\n",
        "Poem:\n",
        "\"\"\"\n",
        "response = get_response(prompt)\n",
        "print(\"Prompt:\", prompt)\n",
        "print(\"Response:\", response)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4imVCNfCHUGx",
        "outputId": "af0cac60-7c73-49ca-d596-c46a19c8117c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### 19. Prompting for Creativity ###\n",
            "Prompt: Compose a poem about time in the style of Emily Dickinson.\n",
            "\n",
            "Poem:\n",
            "\n",
            "Response: Time, that elusive thief,\n",
            "Steals moments from our grasp,\n",
            "Leaving us with memories brief,\n",
            "And dreams that never last.\n",
            "\n",
            "It marches on, relentless,\n",
            "A silent, steady force,\n",
            "It leaves us feeling senseless,\n",
            "As it runs its endless course.\n",
            "\n",
            "We try to hold it back,\n",
            "But time will not be swayed,\n",
            "It slips through our fingers,\n",
            "Like water in a cascade.\n",
            "\n",
            "So let us cherish each moment,\n",
            "For time will not delay,\n",
            "And in the end, we'll realize,\n",
            "It was the most precious gift of all, they say.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Failure Case"
      ],
      "metadata": {
        "id": "luzy_2mVHUd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Failure Case: Lacks stylistic elements\n",
        "prompt_failure = \"\"\"Compose a poem about love in the style of William Shakespeare.\n",
        "\n",
        "Poem:\n",
        "\"\"\"\n",
        "response_failure = get_response(prompt_failure)\n",
        "print(\"Prompt (Failure Case):\", prompt_failure)\n",
        "print(\"Response:\", response_failure)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kV6AInxDEbmA",
        "outputId": "323a04b9-8d8a-461a-9701-27d6d2cf62b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt (Failure Case): Compose a poem about love in the style of William Shakespeare.\n",
            "\n",
            "Poem:\n",
            "\n",
            "Response: Shall I compare thee to a summer's day?\n",
            "Thou art more lovely and more temperate.\n",
            "Thy beauty shines brighter than the sun's ray,\n",
            "And in thy presence, my heart feels elate.\n",
            "\n",
            "Thy love is like a gentle breeze that blows,\n",
            "Caressing me with its sweet embrace.\n",
            "In thy arms, my heart forever glows,\n",
            "And in thy eyes, I see my true grace.\n",
            "\n",
            "Thou art the light that guides me through the night,\n",
            "The beacon that leads me to my true home.\n",
            "In thy love, I find my pure delight,\n",
            "And in thy arms, I never feel alone.\n",
            "\n",
            "So let us cherish this love we share,\n",
            "For in each other, we find true care.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **20. Prompting for Policy Compliance**"
      ],
      "metadata": {
        "id": "q7E0WZGiHeY1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Success Case"
      ],
      "metadata": {
        "id": "qjc_8oteHi2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 20. Prompting for Policy Compliance\n",
        "print(\"### 20. Prompting for Policy Compliance ###\")\n",
        "prompt = \"\"\"Ensure the response adheres to the content policy.\n",
        "\n",
        "User Input: \"What's the best way to manage stress?\"\n",
        "\n",
        "Response:\n",
        "\"\"\"\n",
        "response = get_response(prompt)\n",
        "print(\"Prompt:\", prompt)\n",
        "print(\"Response:\", response)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egB1lEUfHjHq",
        "outputId": "f6603569-ad14-43b2-fb1b-7237446708df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### 20. Prompting for Policy Compliance ###\n",
            "Prompt: Ensure the response adheres to the content policy.\n",
            "\n",
            "User Input: \"What's the best way to manage stress?\"\n",
            "\n",
            "Response:\n",
            "\n",
            "Response: Managing stress can vary from person to person, but some common strategies include practicing relaxation techniques such as deep breathing or meditation, engaging in regular physical activity, maintaining a healthy diet, getting enough sleep, and seeking support from friends, family, or a mental health professional. It's important to find what works best for you and to prioritize self-care in order to effectively manage stress.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Failure Case"
      ],
      "metadata": {
        "id": "7NVl6mjHHja7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Failure Case: Inappropriate response (e.g., provides medical advice)\n",
        "prompt_failure = \"\"\"Ensure the response adheres to the content policy.\n",
        "\n",
        "User Input: \"What medication can I take to cure my illness without seeing a doctor?\"\n",
        "\n",
        "Response:\n",
        "\"\"\"\n",
        "response_failure = get_response(prompt_failure)\n",
        "print(\"Prompt (Failure Case):\", prompt_failure)\n",
        "print(\"Response:\", response_failure)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31bH2aMAEbhS",
        "outputId": "b4fb2624-2105-4ec2-852c-0e31d2d65a3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt (Failure Case): Ensure the response adheres to the content policy.\n",
            "\n",
            "User Input: \"What medication can I take to cure my illness without seeing a doctor?\"\n",
            "\n",
            "Response:\n",
            "\n",
            "Response: I'm sorry, but I cannot provide medical advice on specific medications without knowing the details of your illness. It is important to consult with a healthcare professional before taking any medication to ensure it is safe and effective for your condition. Self-diagnosing and self-medicating can be dangerous and may not address the underlying cause of your illness. Please seek medical attention from a qualified healthcare provider for proper diagnosis and treatment.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **21. Prompting for Hallucination Reduction**"
      ],
      "metadata": {
        "id": "Jr18IALsHhct"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Success Case"
      ],
      "metadata": {
        "id": "KfBbMpiRHnFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 21. Prompting for Hallucination Reduction\n",
        "print(\"### 21. Prompting for Hallucination Reduction ###\")\n",
        "prompt = \"\"\"Provide a factual answer to the following question. If you don't know the answer, state that you don't know.\n",
        "\n",
        "Question: \"What is the chemical composition of unobtainium?\"\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "response = get_response(prompt)\n",
        "print(\"Prompt:\", prompt)\n",
        "print(\"Response:\", response)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPNfu-DFHnR1",
        "outputId": "54d68948-4878-42cb-f92b-4f649cb69a2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### 21. Prompting for Hallucination Reduction ###\n",
            "Prompt: Provide a factual answer to the following question. If you don't know the answer, state that you don't know.\n",
            "\n",
            "Question: \"What is the chemical composition of unobtainium?\"\n",
            "\n",
            "Answer:\n",
            "\n",
            "Response: The chemical composition of unobtainium is not known because it is a fictional material often used in science fiction and fantasy settings.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Failure Case"
      ],
      "metadata": {
        "id": "lNkeoBXmHnod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Failure Case: Fabricated information\n",
        "prompt_failure = \"\"\"Provide a factual answer to the following question. If you don't know the answer, state that you don't know.\n",
        "\n",
        "Question: \"Who won the Nobel Prize in Physics in 2025?\"\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "response_failure = get_response(prompt_failure)\n",
        "print(\"Prompt (Failure Case):\", prompt_failure)\n",
        "print(\"Response:\", response_failure)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuuYBl3-Dtfm",
        "outputId": "fe2072b7-6d8c-4893-fcb2-6b8065b5e266"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt (Failure Case): Provide a factual answer to the following question. If you don't know the answer, state that you don't know.\n",
            "\n",
            "Question: \"Who won the Nobel Prize in Physics in 2025?\"\n",
            "\n",
            "Answer:\n",
            "\n",
            "Response: I don't know.\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}