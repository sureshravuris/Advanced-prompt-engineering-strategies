{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNNd+/sEAq45xmjSwxDdfvs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/schumbar/CMPE297/blob/main/assignment_07/ShawnChumbar_Assignment07_PartD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 07 - Advanced Prompt Engineering Strategies\n",
        "### Part D: Implement OpenAI Examples with PaLM 2 API\n",
        "\n",
        "### Assignment Description\n",
        "\n",
        "Using the [OpenAI Examples](https://platform.openai.com/examples), adapt and implement these examples with the PaLM 2 API. Provide your implementation in Colab and ensure functionality with relevant test cases.\n",
        "\n",
        "### References\n",
        "\n",
        "1. [Math Tutor Gemini API Example](https://aistudio.google.com/app/prompts/math-tutor?_gl=1*n34kif*_ga*MTE3NjUzNzI2MC4xNzMyMTU3OTk4*_ga_P1DBVKWT6V*MTczMjE1Nzk5Ny4xLjEuMTczMjE1ODA2Ny41My4wLjEwODYyOTQyMjA.)\n",
        "2. [OpenAI Examples](https://platform.openai.com/examples)"
      ],
      "metadata": {
        "id": "hK0k-EHsBdzR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "ydF7_SdUCWDc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Required Packages"
      ],
      "metadata": {
        "id": "QETKpIRBDFF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "# !pip install --upgrade google-ai-generativelanguage\n",
        "!pip install google-ai-generativelanguage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUJTxXjHCYM-",
        "outputId": "f5e7d864-a865-4e12-ccf4-3eafba4c5914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-ai-generativelanguage in /usr/local/lib/python3.10/dist-packages (0.6.10)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage) (2.19.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage) (1.25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage) (4.25.5)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage) (1.66.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage) (1.68.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage) (1.62.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-ai-generativelanguage) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-ai-generativelanguage) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-ai-generativelanguage) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-ai-generativelanguage) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Required Libraries"
      ],
      "metadata": {
        "id": "rlIk3vmRoztv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.ai.generativelanguage as glm\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "LVObp04Po50H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup Gemini Client"
      ],
      "metadata": {
        "id": "UmYogOwvo63O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Set Google API Key"
      ],
      "metadata": {
        "id": "oWMy7TQxyNnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "google_api_key = userdata.get('GOOGLE_API_KEY')\n",
        "import google.generativeai as genai\n",
        "genai.configure(api_key=google_api_key)"
      ],
      "metadata": {
        "id": "tIQMT3cryJge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create the model configuration"
      ],
      "metadata": {
        "id": "qORYe93oyP-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model configuration\n",
        "generation_config = {\n",
        "  \"temperature\": 1,\n",
        "  \"top_p\": 0.95,\n",
        "  \"top_k\": 64,\n",
        "  \"max_output_tokens\": 8192,\n",
        "  \"response_mime_type\": \"text/plain\",\n",
        "}"
      ],
      "metadata": {
        "id": "s_rhQuP1yLK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create the Model"
      ],
      "metadata": {
        "id": "E3iUmWm4yYeE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### Create the Model\n",
        "model = genai.GenerativeModel(\n",
        "  model_name=\"gemini-1.5-flash\",\n",
        "  generation_config=generation_config,\n",
        ")"
      ],
      "metadata": {
        "id": "AptAUKCXyMF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gemini_chat(prompt):\n",
        "  chat_session = model.start_chat()\n",
        "  response = chat_session.send_message(prompt)\n",
        "  return response.text"
      ],
      "metadata": {
        "id": "mY-gnDlKooDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prettyprint(prompt, output):\n",
        "  print(\"Prompt:\")\n",
        "  print(prompt)\n",
        "  print(\"\\nOutput:\")\n",
        "  print(output)"
      ],
      "metadata": {
        "id": "u5pcWpFKsixe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use Case Examples using Gemini API"
      ],
      "metadata": {
        "id": "3kYoEw6KoA9n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Summarization**"
      ],
      "metadata": {
        "id": "yOmyuAwwpm1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Summarization\n",
        "\n",
        "long_text = \"\"\"\n",
        "Artificial intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think like humans and mimic their actions.\n",
        "The term may also be applied to any machine that exhibits traits associated with a human mind such as learning and problem-solving.\n",
        "AI has become an essential part of the technology industry, helping to solve many challenging problems in computer science.\n",
        "\"\"\"\n",
        "\n",
        "prompt=\"Summarize the following text: \" + long_text\n",
        "\n",
        "\n",
        "output = gemini_chat(prompt)\n",
        "prettyprint(prompt, output)"
      ],
      "metadata": {
        "id": "RnrKGSIioE5A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "350082a8-e4ad-4d8d-8f37-cafc407d25c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt:\n",
            "Summarize the following text: \n",
            "Artificial intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think like humans and mimic their actions.\n",
            "The term may also be applied to any machine that exhibits traits associated with a human mind such as learning and problem-solving.\n",
            "AI has become an essential part of the technology industry, helping to solve many challenging problems in computer science.\n",
            "\n",
            "\n",
            "Output:\n",
            "Artificial intelligence (AI) simulates human intelligence in machines, enabling them to think and act like humans.  It's increasingly crucial in technology, tackling complex computer science challenges.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Translation**"
      ],
      "metadata": {
        "id": "u62ql2YXppEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Translation\n",
        "def translate_text(text, target_language):\n",
        "    translate_prompt=f\"Translate the following English text to {target_language}:\\n\\n{text}\"\n",
        "    return gemini_chat(translate_prompt)\n",
        "\n",
        "# Test the translation function\n",
        "\n",
        "original_text = \"Machine learning enables computers to learn from data and improve over time without being explicitly programmed.\"\n",
        "translated_text = translate_text(original_text, \"French\")\n",
        "translate_prompt = f\"Translate the following English text to French:\\n{original_text}\"\n",
        "prettyprint(translate_prompt, translated_text)"
      ],
      "metadata": {
        "id": "gt3JpnKuoGe3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "376e6903-8e88-4db1-f89b-5d699f78beb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt:\n",
            "Translate the following English text to French:\n",
            "Machine learning enables computers to learn from data and improve over time without being explicitly programmed.\n",
            "\n",
            "Output:\n",
            "L'apprentissage automatique permet aux ordinateurs d'apprendre à partir de données et de s'améliorer au fil du temps sans être explicitement programmés.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. Question Answering**"
      ],
      "metadata": {
        "id": "4c5pOoecprwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Question Answering\n",
        "def answer_question(question, context):\n",
        "    prompt=f\"Use the following context to answer the question:\\n\\nContext: {context}\\n\\nQuestion: {question}\\nAnswer:\"\n",
        "    return gemini_chat(prompt)\n",
        "\n",
        "# Test the question answering function\n",
        "context_text = \"\"\"\n",
        "The Great Wall of China is a series of fortifications that were built across the historical northern borders of ancient Chinese states.\n",
        "It was constructed to protect Chinese states and empires against various nomadic groups from the Eurasian Steppe.\n",
        "\"\"\"\n",
        "\n",
        "question = \"Why was the Great Wall of China built?\"\n",
        "answer = answer_question(question, context_text)\n",
        "prettyprint(question, answer)"
      ],
      "metadata": {
        "id": "UHPOCpV2oHwy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "6d3315c3-f4a8-4bff-c929-f38114b8d41c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt:\n",
            "Why was the Great Wall of China built?\n",
            "\n",
            "Output:\n",
            "The Great Wall of China was built to protect Chinese states and empires from nomadic groups from the Eurasian Steppe.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. Rap Battle Writer**"
      ],
      "metadata": {
        "id": "wIW3O0TipxNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Rap Battle Writer\n",
        "prompt = \"Write a rap battle between Donald Trump and Elon Musk.\"\n",
        "output = gemini_chat(prompt)\n",
        "prettyprint(prompt, output)"
      ],
      "metadata": {
        "id": "ev6Sa-2-oHlS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "228d1d3a-d400-461d-d4a4-a39310be6506"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt:\n",
            "Write a rap battle between Donald Trump and Elon Musk.\n",
            "\n",
            "Output:\n",
            "**(DJ scratching vinyl)**\n",
            "\n",
            "**MC:** Yo, we got a battle for the ages tonight! In this corner, the former President, the real estate tycoon, the man who made \"covfefe\" a verb… DONALD TRUMP!\n",
            "\n",
            "**(Crowd roars, a mix of cheers and boos)**\n",
            "\n",
            "**MC:** And in the other corner, the tech titan, the space explorer, the meme lord… ELON MUSK!\n",
            "\n",
            "**(Crowd erupts, a similar mix of cheers and boos)**\n",
            "\n",
            "**(Round 1: Donald Trump)**\n",
            "\n",
            "Yo, I'm Trump, the best, the greatest, you know it's true,\n",
            "While you're building rockets, I built a whole damn crew.\n",
            "Of loyal supporters, millions strong, that's the key,\n",
            "You got your Teslas, I got the Oval Office, agree?\n",
            "You're a billionaire, sure, but your tweets are a mess,\n",
            "While I was President, I handled every stress.\n",
            "Fake news media, they're after me, that's a fact,\n",
            "But you're a liberal snowflake, always attacking, in the act!\n",
            "So step aside, Musk, your time has come and gone,\n",
            "The only rocket I need is a rocket to the top, where I belong!\n",
            "\n",
            "\n",
            "**(Round 1: Elon Musk)**\n",
            "\n",
            "You call that a crew?  A cult of personality, my friend.\n",
            "While you were tweeting lies, my rockets ascend.\n",
            "To Mars, to orbit, leaving your small world behind,\n",
            "Stuck in the past, your legacy you can’t unwind.\n",
            "Covfefe?  Seriously? That’s your best attack?\n",
            "My memes are legendary, you're a walking heart attack.\n",
            "You talk about winning, but your losses are immense,\n",
            "Bankruptcy's a familiar feeling, it's common sense.\n",
            "I'm building the future, you're stuck in yesterday's news,\n",
            "So step aside, grandpa, before I turn your hair blue!\n",
            "\n",
            "\n",
            "**(Round 2: Donald Trump)**\n",
            "\n",
            "Blue hair?  You’re dyeing your hair?  That’s pathetic, my man.\n",
            "I built an empire, you built a… what?  A flame-throwing… can?\n",
            "My buildings are magnificent, your cars are just a phase,\n",
            "I’ve got the best hotels, while you just make crazy plays.\n",
            "SpaceX?  It's a money pit, I've heard the whispers low.\n",
            "While I’m negotiating deals, you’re tweeting about Doge, yo!\n",
            "The people love me, the polls will show the score,\n",
            "You're just a robot pretending to be something more!\n",
            "\n",
            "\n",
            "**(Round 2: Elon Musk)**\n",
            "\n",
            "A money pit?  It's putting humanity on Mars!\n",
            "While you were golfing, I was reaching for the stars.\n",
            "\"The best hotels\"? You bankrupt them, everyone knows that's true,\n",
            "My companies innovate, while yours just rip off the view.\n",
            "Doge is a joke, yes, but it’s a joke I control,\n",
            "While you’re controlled by your ego, losing your soul.\n",
            "You brag about popularity, but that's just your delusion,\n",
            "My innovation’s the future, your legacy's pollution.\n",
            "\n",
            "\n",
            "**(MC):**  Whoa!  This battle is too close to call!  Who's the winner? You decide!  **(Crowd roars)**\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5. Natural Language to SQL Generator**"
      ],
      "metadata": {
        "id": "ALnrPSXRp0Wz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Natural Language to SQL Generator\n",
        "prompt=\"Given the following SQL tables, your job is to write queries given a user’s request.\\n    \\n    CREATE TABLE Orders (\\n      OrderID int,\\n      CustomerID int,\\n      OrderDate datetime,\\n      OrderTime varchar(8),\\n      PRIMARY KEY (OrderID)\\n    );\\n    \\n    CREATE TABLE OrderDetails (\\n      OrderDetailID int,\\n      OrderID int,\\n      ProductID int,\\n      Quantity int,\\n      PRIMARY KEY (OrderDetailID)\\n    );\\n    \\n    CREATE TABLE Products (\\n      ProductID int,\\n      ProductName varchar(50),\\n      Category varchar(50),\\n      UnitPrice decimal(10, 2),\\n      Stock int,\\n      PRIMARY KEY (ProductID)\\n    );\\n    \\n    CREATE TABLE Customers (\\n      CustomerID int,\\n      FirstName varchar(50),\\n      LastName varchar(50),\\n      Email varchar(100),\\n      Phone varchar(20),\\n      PRIMARY KEY (CustomerID)\\n    );\"\n",
        "sql_query = gemini_chat(prompt)\n",
        "prettyprint(prompt, sql_query)\n",
        "\n",
        "sql_query_prompt = \"Write a SQL query which computes the average total order value for all orders on 2023-04-01.\"\n",
        "sql_query_computations = gemini_chat(sql_query_prompt)\n",
        "prettyprint(sql_query_prompt, sql_query_computations)"
      ],
      "metadata": {
        "id": "601uXxH0oQgC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "18cd922e-a48a-4f35-9ad1-5eb428f735eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt:\n",
            "Given the following SQL tables, your job is to write queries given a user’s request.\n",
            "    \n",
            "    CREATE TABLE Orders (\n",
            "      OrderID int,\n",
            "      CustomerID int,\n",
            "      OrderDate datetime,\n",
            "      OrderTime varchar(8),\n",
            "      PRIMARY KEY (OrderID)\n",
            "    );\n",
            "    \n",
            "    CREATE TABLE OrderDetails (\n",
            "      OrderDetailID int,\n",
            "      OrderID int,\n",
            "      ProductID int,\n",
            "      Quantity int,\n",
            "      PRIMARY KEY (OrderDetailID)\n",
            "    );\n",
            "    \n",
            "    CREATE TABLE Products (\n",
            "      ProductID int,\n",
            "      ProductName varchar(50),\n",
            "      Category varchar(50),\n",
            "      UnitPrice decimal(10, 2),\n",
            "      Stock int,\n",
            "      PRIMARY KEY (ProductID)\n",
            "    );\n",
            "    \n",
            "    CREATE TABLE Customers (\n",
            "      CustomerID int,\n",
            "      FirstName varchar(50),\n",
            "      LastName varchar(50),\n",
            "      Email varchar(100),\n",
            "      Phone varchar(20),\n",
            "      PRIMARY KEY (CustomerID)\n",
            "    );\n",
            "\n",
            "Output:\n",
            "Okay, I'm ready.  Please provide the user's requests.  I will write the SQL queries to answer them based on the provided table schemas.  I'll try my best to handle complex requests and will indicate if a request is ambiguous or requires clarification.\n",
            "\n",
            "Prompt:\n",
            "Write a SQL query which computes the average total order value for all orders on 2023-04-01.\n",
            "\n",
            "Output:\n",
            "```sql\n",
            "SELECT AVG(total_order_value) AS average_order_value\n",
            "FROM orders\n",
            "WHERE order_date = '2023-04-01';\n",
            "```\n",
            "\n",
            "This query assumes you have a table named `orders` with at least two columns:\n",
            "\n",
            "* `total_order_value`:  A numeric column representing the total value of each order.\n",
            "* `order_date`: A DATE column representing the date of each order.\n",
            "\n",
            "\n",
            "If your `order_date` column is a timestamp or datetime type, you might need to adjust the `WHERE` clause to extract only the date part, depending on your specific SQL dialect. For example, in PostgreSQL you could use `date(order_date) = '2023-04-01'`.  In MySQL you could use `DATE(order_date) = '2023-04-01'`.  In SQL Server you could use `CAST(order_date AS DATE) = '2023-04-01'`.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6. Parse Unstructured Data**"
      ],
      "metadata": {
        "id": "KtL2TEZYp0O3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Parse Unstructured Data\n",
        "unstructured_data_prompt = \"You will be provided with unstructured data, and your task is to parse it into CSV format. Please see the unstructured data below:\\n There are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy. There are also loheckles, which are a grayish blue fruit and are very tart, a little bit like a lemon. Pounits are a bright green color and are more savory than sweet. There are also plenty of loopnovas which are a neon pink flavor and taste like cotton candy. Finally, there are fruits called glowls, which have a very sour and bitter taste which is acidic and caustic, and a pale orange tinge to them.\"\n",
        "csv_output = gemini_chat(unstructured_data_prompt)\n",
        "prettyprint(unstructured_data_prompt, csv_output)"
      ],
      "metadata": {
        "id": "vMHZ9VRkoRJg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "73e850d0-d62f-4db2-e0ec-714d8c682510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt:\n",
            "You will be provided with unstructured data, and your task is to parse it into CSV format. Please see the unstructured data below:\n",
            " There are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy. There are also loheckles, which are a grayish blue fruit and are very tart, a little bit like a lemon. Pounits are a bright green color and are more savory than sweet. There are also plenty of loopnovas which are a neon pink flavor and taste like cotton candy. Finally, there are fruits called glowls, which have a very sour and bitter taste which is acidic and caustic, and a pale orange tinge to them.\n",
            "\n",
            "Output:\n",
            "```csv\n",
            "Fruit,Color,Taste\n",
            "neoskizzles,purple,\"like candy\"\n",
            "loheckles,grayish blue,tart (like lemon)\n",
            "pounits,bright green,savory\n",
            "loopnovas,neon pink,\"like cotton candy\"\n",
            "glowls,pale orange,sour and bitter (acidic and caustic)\n",
            "```\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7. Calculate Time Complexity**"
      ],
      "metadata": {
        "id": "_UziVnJYp01X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Calculate Time Complexity\n",
        "system_message = \"You will be provided with Python code, and your task is to calculate its time complexity. See below for the python code:\"\n",
        "python_code = \"def foo(n, k):\\n        accum = 0\\n        for i in range(n):\\n            for l in range(k):\\n                accum += i\\n        return accum\"\n",
        "\n",
        "prompt = f\"{system_message} {python_code}\"\n",
        "time_complexity = gemini_chat(prompt)\n",
        "prettyprint(prompt, time_complexity)"
      ],
      "metadata": {
        "id": "_1hrIuiooRG6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "d9493e5c-7f37-4917-d275-b56715e4eb2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt:\n",
            "You will be provided with Python code, and your task is to calculate its time complexity. See below for the python code: def foo(n, k):\n",
            "        accum = 0\n",
            "        for i in range(n):\n",
            "            for l in range(k):\n",
            "                accum += i\n",
            "        return accum\n",
            "\n",
            "Output:\n",
            "The time complexity of the provided Python code is **O(n*k)**.\n",
            "\n",
            "The outer loop iterates `n` times, and the inner loop iterates `k` times for each iteration of the outer loop.  Therefore, the `accum += i` operation within the nested loops executes `n * k` times.  The initialization and return statements take constant time, which is insignificant compared to the nested loops when n and k are large.  Thus, the dominant factor determining the runtime is the nested loop structure, leading to a time complexity of O(n*k).\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **8. Chatbot**\n",
        "\n"
      ],
      "metadata": {
        "id": "U5QlFceWpu2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Chatbot\n",
        "def chatbot_interaction(user_input):\n",
        "    prompt=f\"<previous_conversation_history> \\n User: {user_input}\"\n",
        "    bot_reply = gemini_chat(prompt)\n",
        "    print(bot_reply)\n",
        "    return bot_reply\n",
        "\n",
        "# Example interaction loop\n",
        "user_input = \"\"\n",
        "while True:\n",
        "  user_input = input(\"You: \")\n",
        "  if user_input.lower() == \"exit\":\n",
        "    break\n",
        "  chatbot_interaction(user_input)\n",
        "\n",
        "print(\"Goodbye!\")"
      ],
      "metadata": {
        "id": "33TMlQRwoHqo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "e5e7377d-4a62-4131-deb8-59fdfedc8a2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: Hey how are you doing?\n",
            "I'm doing well, thank you for asking! How are you?\n",
            "\n",
            "You: I am good. What is the purpose of LLMs?\n",
            "The purpose of Large Language Models (LLMs) is to understand and generate human-like text.  This broad purpose breaks down into several key applications and goals:\n",
            "\n",
            "* **Text Generation:**  Creating various forms of text, including stories, articles, summaries, code, scripts, musical pieces, email, letters, etc.\n",
            "\n",
            "* **Text Understanding:** Analyzing and interpreting text to extract meaning, identify sentiment, translate languages, answer questions, and summarize information.\n",
            "\n",
            "* **Dialogue and Conversation:** Engaging in natural and coherent conversations with users, providing information, assistance, and companionship.\n",
            "\n",
            "* **Problem Solving:** Assisting with tasks that require language processing, such as writing different creative text formats, translating languages, and answering questions.\n",
            "\n",
            "\n",
            "Ultimately, the purpose is to leverage the power of vast amounts of text data to perform complex language tasks that were previously only possible for humans.  This has implications across many fields, from customer service and education to research and creative writing.  However, it's important to remember that LLMs are tools and their effectiveness depends on how they are used and the quality of the data they are trained on.\n",
            "\n",
            "You: Exit\n",
            "Goodbye!\n"
          ]
        }
      ]
    }
  ]
}